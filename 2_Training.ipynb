{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision Nanodegree\n",
    "\n",
    "## Project: Image Captioning\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will train your CNN-RNN model.  \n",
    "\n",
    "You are welcome and encouraged to try out many different architectures and hyperparameters when searching for a good model.\n",
    "\n",
    "This does have the potential to make the project quite messy!  Before submitting your project, make sure that you clean up:\n",
    "- the code you write in this notebook.  The notebook should describe how to train a single CNN-RNN architecture, corresponding to your final choice of hyperparameters.  You should structure the notebook so that the reviewer can replicate your results by running the code in this notebook.  \n",
    "- the output of the code cell in **Step 2**.  The output should show the output obtained when training the model from scratch.\n",
    "\n",
    "This notebook **will be graded**.  \n",
    "\n",
    "Feel free to use the links below to navigate the notebook:\n",
    "- [Step 1](#step1): Training Setup\n",
    "- [Step 2](#step2): Train your Model\n",
    "- [Step 3](#step3): (Optional) Validate your Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step1'></a>\n",
    "## Step 1: Training Setup\n",
    "\n",
    "In this step of the notebook, you will customize the training of your CNN-RNN model by specifying hyperparameters and setting other options that are important to the training procedure.  The values you set now will be used when training your model in **Step 2** below.\n",
    "\n",
    "You should only amend blocks of code that are preceded by a `TODO` statement.  **Any code blocks that are not preceded by a `TODO` statement should not be modified**.\n",
    "\n",
    "### Task #1\n",
    "\n",
    "Begin by setting the following variables:\n",
    "- `batch_size` - the batch size of each training batch.  It is the number of image-caption pairs used to amend the model weights in each training step. \n",
    "- `vocab_threshold` - the minimum word count threshold.  Note that a larger threshold will result in a smaller vocabulary, whereas a smaller threshold will include rarer words and result in a larger vocabulary.  \n",
    "- `vocab_from_file` - a Boolean that decides whether to load the vocabulary from file. \n",
    "- `embed_size` - the dimensionality of the image and word embeddings.  \n",
    "- `hidden_size` - the number of features in the hidden state of the RNN decoder.  \n",
    "- `num_epochs` - the number of epochs to train the model.  We recommend that you set `num_epochs=3`, but feel free to increase or decrease this number as you wish.  [This paper](https://arxiv.org/pdf/1502.03044.pdf) trained a captioning model on a single state-of-the-art GPU for 3 days, but you'll soon see that you can get reasonable results in a matter of a few hours!  (_But of course, if you want your model to compete with current research, you will have to train for much longer._)\n",
    "- `save_every` - determines how often to save the model weights.  We recommend that you set `save_every=1`, to save the model weights after each epoch.  This way, after the `i`th epoch, the encoder and decoder weights will be saved in the `models/` folder as `encoder-i.pkl` and `decoder-i.pkl`, respectively.\n",
    "- `print_every` - determines how often to print the batch loss to the Jupyter notebook while training.  Note that you **will not** observe a monotonic decrease in the loss function while training - this is perfectly fine and completely expected!  You are encouraged to keep this at its default value of `100` to avoid clogging the notebook, but feel free to change it.\n",
    "- `log_file` - the name of the text file containing - for every step - how the loss and perplexity evolved during training.\n",
    "\n",
    "If you're not sure where to begin to set some of the values above, you can peruse [this paper](https://arxiv.org/pdf/1502.03044.pdf) and [this paper](https://arxiv.org/pdf/1411.4555.pdf) for useful guidance!  **To avoid spending too long on this notebook**, you are encouraged to consult these suggested research papers to obtain a strong initial guess for which hyperparameters are likely to work best.  Then, train a single model, and proceed to the next notebook (**3_Inference.ipynb**).  If you are unhappy with your performance, you can return to this notebook to tweak the hyperparameters (and/or the architecture in **model.py**) and re-train your model.\n",
    "\n",
    "### Question 1\n",
    "\n",
    "**Question:** Describe your CNN-RNN architecture in detail.  With this architecture in mind, how did you select the values of the variables in Task 1?  If you consulted a research paper detailing a successful implementation of an image captioning model, please provide the reference.\n",
    "\n",
    "**Answer:** The CNN encoder was kept as resnet50 and an LSTM decoder as mentioned in https://arxiv.org/pdf/1411.4555.pdf was implemented. However, dropout was not implemented. The parameters of task 1 were selected based on suggestions in research papers and are described below;\n",
    "batch_size: Kept at 64 as suggested in https://arxiv.org/pdf/1502.03044.pdf.\n",
    "vocab_threshold: Selected as 5 which gave a vocabulary size of about 10000 as suggested in https://arxiv.org/pdf/1502.03044.pdf.\n",
    "embed_size and hidden_size: Kept at 512 as suggested in https://arxiv.org/pdf/1411.4555.pdf.\n",
    "\n",
    "As this architecture and parameter settings gave decent performance, I did not tweak them further.\n",
    "\n",
    "\n",
    "### (Optional) Task #2\n",
    "\n",
    "Note that we have provided a recommended image transform `transform_train` for pre-processing the training images, but you are welcome (and encouraged!) to modify it as you wish.  When modifying this transform, keep in mind that:\n",
    "- the images in the dataset have varying heights and widths, and \n",
    "- if using a pre-trained model, you must perform the corresponding appropriate normalization.\n",
    "\n",
    "### Question 2\n",
    "\n",
    "**Question:** How did you select the transform in `transform_train`?  If you left the transform at its provided value, why do you think that it is a good choice for your CNN architecture?\n",
    "\n",
    "**Answer:** I left the transform at its provided value especially because it would be in accordance with the selected default CNN encoder of Resnet50 and also because the operations are pretty much standard for a reasonable performance and computation. However, resizing to different sizes could be analyzed to test the impact of resolution but this was not implemented. \n",
    "\n",
    "### Task #3\n",
    "\n",
    "Next, you will specify a Python list containing the learnable parameters of the model.  For instance, if you decide to make all weights in the decoder trainable, but only want to train the weights in the embedding layer of the encoder, then you should set `params` to something like:\n",
    "```\n",
    "params = list(decoder.parameters()) + list(encoder.embed.parameters()) \n",
    "```\n",
    "\n",
    "### Question 3\n",
    "\n",
    "**Question:** How did you select the trainable parameters of your architecture?  Why do you think this is a good choice?\n",
    "\n",
    "**Answer:** Only the embedding layer of the encoder and the full decoder was trained. Since the Resnet50 was pretrained so only the embedding layer had to be trained to effectively resize the features to a fixed size for input to the LSTM decoder. The decoder had to be trained from scratch therefore all of its parameters were trained.\n",
    "\n",
    "### Task #4\n",
    "\n",
    "Finally, you will select an [optimizer](http://pytorch.org/docs/master/optim.html#torch.optim.Optimizer).\n",
    "\n",
    "### Question 4\n",
    "\n",
    "**Question:** How did you select the optimizer used to train your model?\n",
    "\n",
    "**Answer:** The optimizer was selected as Adam as suggested in https://arxiv.org/pdf/1502.03044.pdf to have an adaptive learning rate instead of a fixed rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "Vocabulary successfully loaded from vocab.pkl file!\n",
      "loading annotations into memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/414113 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 354/414113 [00:00<01:57, 3536.14it/s]\u001b[A\n",
      "  0%|          | 789/414113 [00:00<01:50, 3746.27it/s]\u001b[A\n",
      "  0%|          | 1231/414113 [00:00<01:45, 3924.40it/s]\u001b[A\n",
      "  0%|          | 1674/414113 [00:00<01:41, 4062.25it/s]\u001b[A\n",
      "  1%|          | 2108/414113 [00:00<01:39, 4140.85it/s]\u001b[A\n",
      "  1%|          | 2548/414113 [00:00<01:37, 4212.17it/s]\u001b[A\n",
      "  1%|          | 2980/414113 [00:00<01:36, 4243.83it/s]\u001b[A\n",
      "  1%|          | 3410/414113 [00:00<01:36, 4258.27it/s]\u001b[A\n",
      "  1%|          | 3845/414113 [00:00<01:35, 4284.41it/s]\u001b[A\n",
      "  1%|          | 4291/414113 [00:01<01:34, 4335.30it/s]\u001b[A\n",
      "  1%|          | 4727/414113 [00:01<01:34, 4340.76it/s]\u001b[A\n",
      "  1%|          | 5173/414113 [00:01<01:33, 4373.93it/s]\u001b[A\n",
      "  1%|▏         | 5616/414113 [00:01<01:33, 4390.58it/s]\u001b[A\n",
      "  1%|▏         | 6052/414113 [00:01<01:37, 4197.98it/s]\u001b[A\n",
      "  2%|▏         | 6484/414113 [00:01<01:36, 4233.66it/s]\u001b[A\n",
      "  2%|▏         | 6922/414113 [00:01<01:35, 4275.85it/s]\u001b[A\n",
      "  2%|▏         | 7350/414113 [00:01<01:35, 4262.37it/s]\u001b[A\n",
      "  2%|▏         | 7793/414113 [00:01<01:34, 4311.12it/s]\u001b[A\n",
      "  2%|▏         | 8229/414113 [00:01<01:33, 4325.36it/s]\u001b[A\n",
      "  2%|▏         | 8662/414113 [00:02<01:34, 4306.30it/s]\u001b[A\n",
      "  2%|▏         | 9093/414113 [00:02<01:35, 4253.19it/s]\u001b[A\n",
      "  2%|▏         | 9519/414113 [00:02<01:35, 4214.68it/s]\u001b[A\n",
      "  2%|▏         | 9941/414113 [00:02<01:37, 4166.13it/s]\u001b[A\n",
      "  3%|▎         | 10365/414113 [00:02<01:36, 4187.36it/s]\u001b[A\n",
      "  3%|▎         | 10794/414113 [00:02<01:35, 4215.52it/s]\u001b[A\n",
      "  3%|▎         | 11222/414113 [00:02<01:35, 4234.64it/s]\u001b[A\n",
      "  3%|▎         | 11646/414113 [00:02<01:35, 4232.69it/s]\u001b[A\n",
      "  3%|▎         | 12070/414113 [00:02<01:36, 4175.34it/s]\u001b[A\n",
      "  3%|▎         | 12488/414113 [00:02<01:37, 4138.40it/s]\u001b[A\n",
      "  3%|▎         | 12923/414113 [00:03<01:35, 4198.72it/s]\u001b[A\n",
      "  3%|▎         | 13360/414113 [00:03<01:34, 4246.42it/s]\u001b[A\n",
      "  3%|▎         | 13786/414113 [00:03<01:34, 4237.76it/s]\u001b[A\n",
      "  3%|▎         | 14211/414113 [00:03<01:34, 4230.62it/s]\u001b[A\n",
      "  4%|▎         | 14657/414113 [00:03<01:32, 4295.26it/s]\u001b[A\n",
      "  4%|▎         | 15102/414113 [00:03<01:31, 4339.08it/s]\u001b[A\n",
      "  4%|▍         | 15551/414113 [00:03<01:30, 4382.60it/s]\u001b[A\n",
      "  4%|▍         | 15996/414113 [00:03<01:30, 4400.86it/s]\u001b[A\n",
      "  4%|▍         | 16439/414113 [00:03<01:30, 4407.56it/s]\u001b[A\n",
      "  4%|▍         | 16880/414113 [00:03<01:30, 4386.87it/s]\u001b[A\n",
      "  4%|▍         | 17320/414113 [00:04<01:30, 4389.17it/s]\u001b[A\n",
      "  4%|▍         | 17769/414113 [00:04<01:29, 4417.47it/s]\u001b[A\n",
      "  4%|▍         | 18211/414113 [00:04<01:29, 4416.42it/s]\u001b[A\n",
      "  5%|▍         | 18658/414113 [00:04<01:29, 4429.50it/s]\u001b[A\n",
      "  5%|▍         | 19102/414113 [00:04<01:29, 4426.76it/s]\u001b[A\n",
      "  5%|▍         | 19558/414113 [00:04<01:28, 4462.76it/s]\u001b[A\n",
      "  5%|▍         | 20005/414113 [00:04<01:28, 4448.55it/s]\u001b[A\n",
      "  5%|▍         | 20454/414113 [00:04<01:28, 4458.63it/s]\u001b[A\n",
      "  5%|▌         | 20900/414113 [00:04<01:31, 4278.82it/s]\u001b[A\n",
      "  5%|▌         | 21330/414113 [00:04<01:31, 4280.96it/s]\u001b[A\n",
      "  5%|▌         | 21770/414113 [00:05<01:30, 4313.06it/s]\u001b[A\n",
      "  5%|▌         | 22215/414113 [00:05<01:30, 4351.05it/s]\u001b[A\n",
      "  5%|▌         | 22658/414113 [00:05<01:29, 4373.96it/s]\u001b[A\n",
      "  6%|▌         | 23107/414113 [00:05<01:28, 4407.26it/s]\u001b[A\n",
      "  6%|▌         | 23549/414113 [00:05<01:28, 4394.57it/s]\u001b[A\n",
      "  6%|▌         | 23999/414113 [00:05<01:28, 4424.27it/s]\u001b[A\n",
      "  6%|▌         | 24452/414113 [00:05<01:27, 4455.10it/s]\u001b[A\n",
      "  6%|▌         | 24898/414113 [00:05<01:27, 4448.07it/s]\u001b[A\n",
      "  6%|▌         | 25343/414113 [00:05<01:28, 4411.33it/s]\u001b[A\n",
      "  6%|▌         | 25801/414113 [00:05<01:27, 4457.60it/s]\u001b[A\n",
      "  6%|▋         | 26248/414113 [00:06<01:26, 4460.15it/s]\u001b[A\n",
      "  6%|▋         | 26702/414113 [00:06<01:26, 4483.02it/s]\u001b[A\n",
      "  7%|▋         | 27151/414113 [00:06<01:26, 4465.51it/s]\u001b[A\n",
      "  7%|▋         | 27598/414113 [00:06<01:26, 4454.05it/s]\u001b[A\n",
      "  7%|▋         | 28049/414113 [00:06<01:26, 4468.37it/s]\u001b[A\n",
      "  7%|▋         | 28503/414113 [00:06<01:25, 4486.99it/s]\u001b[A\n",
      "  7%|▋         | 28952/414113 [00:06<01:26, 4469.94it/s]\u001b[A\n",
      "  7%|▋         | 29400/414113 [00:06<01:27, 4417.61it/s]\u001b[A\n",
      "  7%|▋         | 29842/414113 [00:06<01:27, 4386.09it/s]\u001b[A\n",
      "  7%|▋         | 30281/414113 [00:06<01:28, 4350.30it/s]\u001b[A\n",
      "  7%|▋         | 30717/414113 [00:07<01:28, 4335.50it/s]\u001b[A\n",
      "  8%|▊         | 31151/414113 [00:07<01:28, 4333.53it/s]\u001b[A\n",
      "  8%|▊         | 31603/414113 [00:07<01:27, 4386.41it/s]\u001b[A\n",
      "  8%|▊         | 32042/414113 [00:07<01:27, 4381.78it/s]\u001b[A\n",
      "  8%|▊         | 32489/414113 [00:07<01:26, 4406.45it/s]\u001b[A\n",
      "  8%|▊         | 32930/414113 [00:07<01:27, 4366.30it/s]\u001b[A\n",
      "  8%|▊         | 33370/414113 [00:07<01:27, 4373.44it/s]\u001b[A\n",
      "  8%|▊         | 33817/414113 [00:07<01:26, 4399.46it/s]\u001b[A\n",
      "  8%|▊         | 34260/414113 [00:07<01:26, 4406.70it/s]\u001b[A\n",
      "  8%|▊         | 34701/414113 [00:07<01:26, 4363.06it/s]\u001b[A\n",
      "  8%|▊         | 35141/414113 [00:08<01:26, 4372.43it/s]\u001b[A\n",
      "  9%|▊         | 35581/414113 [00:08<01:26, 4380.63it/s]\u001b[A\n",
      "  9%|▊         | 36020/414113 [00:08<01:26, 4375.17it/s]\u001b[A\n",
      "  9%|▉         | 36458/414113 [00:08<01:26, 4370.33it/s]\u001b[A\n",
      "  9%|▉         | 36896/414113 [00:08<01:26, 4358.20it/s]\u001b[A\n",
      "  9%|▉         | 37332/414113 [00:08<01:27, 4321.37it/s]\u001b[A\n",
      "  9%|▉         | 37773/414113 [00:08<01:26, 4345.72it/s]\u001b[A\n",
      "  9%|▉         | 38214/414113 [00:08<01:26, 4364.55it/s]\u001b[A\n",
      "  9%|▉         | 38651/414113 [00:08<01:26, 4348.84it/s]\u001b[A\n",
      "  9%|▉         | 39086/414113 [00:08<01:26, 4315.37it/s]\u001b[A\n",
      " 10%|▉         | 39518/414113 [00:09<01:27, 4285.30it/s]\u001b[A\n",
      " 10%|▉         | 39950/414113 [00:09<01:27, 4293.41it/s]\u001b[A\n",
      " 10%|▉         | 40380/414113 [00:09<01:27, 4284.64it/s]\u001b[A\n",
      " 10%|▉         | 40822/414113 [00:09<01:26, 4321.69it/s]\u001b[A\n",
      " 10%|▉         | 41258/414113 [00:09<01:26, 4331.24it/s]\u001b[A\n",
      " 10%|█         | 41693/414113 [00:09<01:25, 4333.98it/s]\u001b[A\n",
      " 10%|█         | 42127/414113 [00:09<01:25, 4335.09it/s]\u001b[A\n",
      " 10%|█         | 42561/414113 [00:09<01:27, 4266.99it/s]\u001b[A\n",
      " 10%|█         | 42988/414113 [00:09<01:27, 4235.68it/s]\u001b[A\n",
      " 10%|█         | 43417/414113 [00:10<01:27, 4251.66it/s]\u001b[A\n",
      " 11%|█         | 43844/414113 [00:10<01:27, 4254.48it/s]\u001b[A\n",
      " 11%|█         | 44283/414113 [00:10<01:26, 4291.91it/s]\u001b[A\n",
      " 11%|█         | 44713/414113 [00:10<01:26, 4260.56it/s]\u001b[A\n",
      " 11%|█         | 45146/414113 [00:10<01:26, 4278.91it/s]\u001b[A\n",
      " 11%|█         | 45582/414113 [00:10<01:25, 4299.87it/s]\u001b[A\n",
      " 11%|█         | 46016/414113 [00:10<01:25, 4310.94it/s]\u001b[A\n",
      " 11%|█         | 46457/414113 [00:10<01:24, 4337.11it/s]\u001b[A\n",
      " 11%|█▏        | 46891/414113 [00:10<01:24, 4327.70it/s]\u001b[A\n",
      " 11%|█▏        | 47324/414113 [00:10<01:25, 4301.65it/s]\u001b[A\n",
      " 12%|█▏        | 47755/414113 [00:11<01:25, 4269.42it/s]\u001b[A\n",
      " 12%|█▏        | 48187/414113 [00:11<01:25, 4282.60it/s]\u001b[A\n",
      " 12%|█▏        | 48624/414113 [00:11<01:24, 4308.01it/s]\u001b[A\n",
      " 12%|█▏        | 49055/414113 [00:11<01:24, 4304.18it/s]\u001b[A\n",
      " 12%|█▏        | 49486/414113 [00:11<01:25, 4272.41it/s]\u001b[A\n",
      " 12%|█▏        | 49926/414113 [00:11<01:24, 4309.33it/s]\u001b[A\n",
      " 12%|█▏        | 50365/414113 [00:11<01:23, 4330.90it/s]\u001b[A\n",
      " 12%|█▏        | 50799/414113 [00:11<01:24, 4310.12it/s]\u001b[A\n",
      " 12%|█▏        | 51231/414113 [00:11<01:25, 4263.77it/s]\u001b[A\n",
      " 12%|█▏        | 51658/414113 [00:11<01:25, 4233.91it/s]\u001b[A\n",
      " 13%|█▎        | 52094/414113 [00:12<01:24, 4268.93it/s]\u001b[A\n",
      " 13%|█▎        | 52522/414113 [00:12<01:24, 4270.59it/s]\u001b[A\n",
      " 13%|█▎        | 52950/414113 [00:12<01:25, 4241.77it/s]\u001b[A\n",
      " 13%|█▎        | 53378/414113 [00:12<01:24, 4251.19it/s]\u001b[A\n",
      " 13%|█▎        | 53806/414113 [00:12<01:24, 4258.10it/s]\u001b[A\n",
      " 13%|█▎        | 54240/414113 [00:12<01:24, 4280.97it/s]\u001b[A\n",
      " 13%|█▎        | 54681/414113 [00:12<01:23, 4316.96it/s]\u001b[A\n",
      " 13%|█▎        | 55113/414113 [00:12<01:23, 4311.11it/s]\u001b[A\n",
      " 13%|█▎        | 55549/414113 [00:12<01:22, 4323.36it/s]\u001b[A\n",
      " 14%|█▎        | 55982/414113 [00:12<01:22, 4318.43it/s]\u001b[A\n",
      " 14%|█▎        | 56414/414113 [00:13<01:22, 4311.57it/s]\u001b[A\n",
      " 14%|█▎        | 56846/414113 [00:13<02:25, 2462.52it/s]\u001b[A\n",
      " 14%|█▍        | 57276/414113 [00:13<02:06, 2823.28it/s]\u001b[A\n",
      " 14%|█▍        | 57711/414113 [00:13<01:52, 3155.41it/s]\u001b[A\n",
      " 14%|█▍        | 58157/414113 [00:13<01:42, 3458.30it/s]\u001b[A\n",
      " 14%|█▍        | 58578/414113 [00:13<01:37, 3651.56it/s]\u001b[A\n",
      " 14%|█▍        | 59008/414113 [00:13<01:32, 3822.54it/s]\u001b[A\n",
      " 14%|█▍        | 59433/414113 [00:13<01:30, 3940.61it/s]\u001b[A\n",
      " 14%|█▍        | 59884/414113 [00:14<01:26, 4094.02it/s]\u001b[A\n",
      " 15%|█▍        | 60318/414113 [00:14<01:24, 4163.38it/s]\u001b[A\n",
      " 15%|█▍        | 60748/414113 [00:14<01:24, 4197.28it/s]\u001b[A\n",
      " 15%|█▍        | 61179/414113 [00:14<01:23, 4229.07it/s]\u001b[A\n",
      " 15%|█▍        | 61618/414113 [00:14<01:22, 4274.46it/s]\u001b[A\n",
      " 15%|█▍        | 62058/414113 [00:14<01:21, 4308.91it/s]\u001b[A\n",
      " 15%|█▌        | 62496/414113 [00:14<01:21, 4328.66it/s]\u001b[A\n",
      " 15%|█▌        | 62937/414113 [00:14<01:20, 4351.68it/s]\u001b[A\n",
      " 15%|█▌        | 63374/414113 [00:14<01:20, 4334.76it/s]\u001b[A\n",
      " 15%|█▌        | 63809/414113 [00:14<01:20, 4328.54it/s]\u001b[A\n",
      " 16%|█▌        | 64243/414113 [00:15<01:21, 4296.28it/s]\u001b[A\n",
      " 16%|█▌        | 64674/414113 [00:15<01:21, 4283.11it/s]\u001b[A\n",
      " 16%|█▌        | 65103/414113 [00:15<01:21, 4256.30it/s]\u001b[A\n",
      " 16%|█▌        | 65529/414113 [00:15<01:22, 4243.60it/s]\u001b[A\n",
      " 16%|█▌        | 65960/414113 [00:15<01:21, 4262.26it/s]\u001b[A\n",
      " 16%|█▌        | 66387/414113 [00:15<01:21, 4252.77it/s]\u001b[A\n",
      " 16%|█▌        | 66813/414113 [00:15<01:21, 4240.44it/s]\u001b[A\n",
      " 16%|█▌        | 67238/414113 [00:15<01:22, 4180.68it/s]\u001b[A\n",
      " 16%|█▋        | 67657/414113 [00:15<01:24, 4107.58it/s]\u001b[A\n",
      " 16%|█▋        | 68094/414113 [00:16<01:22, 4180.38it/s]\u001b[A\n",
      " 17%|█▋        | 68513/414113 [00:16<01:22, 4182.49it/s]\u001b[A\n",
      " 17%|█▋        | 68938/414113 [00:16<01:22, 4199.68it/s]\u001b[A\n",
      " 17%|█▋        | 69371/414113 [00:16<01:21, 4236.74it/s]\u001b[A\n",
      " 17%|█▋        | 69797/414113 [00:16<01:21, 4242.29it/s]\u001b[A\n",
      " 17%|█▋        | 70245/414113 [00:16<01:19, 4309.96it/s]\u001b[A\n",
      " 17%|█▋        | 70677/414113 [00:16<01:20, 4290.57it/s]\u001b[A\n",
      " 17%|█▋        | 71115/414113 [00:16<01:19, 4316.20it/s]\u001b[A\n",
      " 17%|█▋        | 71547/414113 [00:16<01:20, 4254.55it/s]\u001b[A\n",
      " 17%|█▋        | 71973/414113 [00:16<01:21, 4189.62it/s]\u001b[A\n",
      " 17%|█▋        | 72393/414113 [00:17<01:22, 4147.19it/s]\u001b[A\n",
      " 18%|█▊        | 72809/414113 [00:17<01:23, 4111.08it/s]\u001b[A\n",
      " 18%|█▊        | 73233/414113 [00:17<01:22, 4147.71it/s]\u001b[A\n",
      " 18%|█▊        | 73677/414113 [00:17<01:20, 4231.25it/s]\u001b[A\n",
      " 18%|█▊        | 74105/414113 [00:17<01:20, 4243.06it/s]\u001b[A\n",
      " 18%|█▊        | 74531/414113 [00:17<01:19, 4246.91it/s]\u001b[A\n",
      " 18%|█▊        | 74961/414113 [00:17<01:19, 4260.32it/s]\u001b[A\n",
      " 18%|█▊        | 75388/414113 [00:17<01:19, 4253.65it/s]\u001b[A\n",
      " 18%|█▊        | 75815/414113 [00:17<01:19, 4255.79it/s]\u001b[A\n",
      " 18%|█▊        | 76241/414113 [00:17<01:20, 4219.05it/s]\u001b[A\n",
      " 19%|█▊        | 76685/414113 [00:18<01:18, 4282.66it/s]\u001b[A\n",
      " 19%|█▊        | 77114/414113 [00:18<01:18, 4279.32it/s]\u001b[A\n",
      " 19%|█▊        | 77547/414113 [00:18<01:18, 4291.82it/s]\u001b[A\n",
      " 19%|█▉        | 77979/414113 [00:18<01:18, 4299.64it/s]\u001b[A\n",
      " 19%|█▉        | 78412/414113 [00:18<01:17, 4307.33it/s]\u001b[A\n",
      " 19%|█▉        | 78845/414113 [00:18<01:17, 4311.50it/s]\u001b[A\n",
      " 19%|█▉        | 79277/414113 [00:18<01:18, 4283.33it/s]\u001b[A\n",
      " 19%|█▉        | 79716/414113 [00:18<01:17, 4314.25it/s]\u001b[A\n",
      " 19%|█▉        | 80150/414113 [00:18<01:17, 4320.16it/s]\u001b[A\n",
      " 19%|█▉        | 80587/414113 [00:18<01:16, 4334.60it/s]\u001b[A\n",
      " 20%|█▉        | 81025/414113 [00:19<01:16, 4346.43it/s]\u001b[A\n",
      " 20%|█▉        | 81460/414113 [00:19<01:16, 4323.72it/s]\u001b[A\n",
      " 20%|█▉        | 81894/414113 [00:19<01:16, 4326.57it/s]\u001b[A\n",
      " 20%|█▉        | 82327/414113 [00:19<01:16, 4309.80it/s]\u001b[A\n",
      " 20%|█▉        | 82769/414113 [00:19<01:16, 4341.69it/s]\u001b[A\n",
      " 20%|██        | 83205/414113 [00:19<01:16, 4345.93it/s]\u001b[A\n",
      " 20%|██        | 83640/414113 [00:19<01:16, 4346.28it/s]\u001b[A\n",
      " 20%|██        | 84085/414113 [00:19<01:15, 4376.82it/s]\u001b[A\n",
      " 20%|██        | 84523/414113 [00:19<01:15, 4355.82it/s]\u001b[A\n",
      " 21%|██        | 84959/414113 [00:19<01:15, 4354.60it/s]\u001b[A\n",
      " 21%|██        | 85401/414113 [00:20<01:15, 4373.00it/s]\u001b[A\n",
      " 21%|██        | 85839/414113 [00:20<01:15, 4339.15it/s]\u001b[A\n",
      " 21%|██        | 86274/414113 [00:20<01:15, 4330.42it/s]\u001b[A\n",
      " 21%|██        | 86723/414113 [00:20<01:14, 4374.27it/s]\u001b[A\n",
      " 21%|██        | 87161/414113 [00:20<01:14, 4366.79it/s]\u001b[A\n",
      " 21%|██        | 87598/414113 [00:20<01:15, 4351.67it/s]\u001b[A\n",
      " 21%|██▏       | 88037/414113 [00:20<01:14, 4361.59it/s]\u001b[A\n",
      " 21%|██▏       | 88474/414113 [00:20<01:14, 4362.99it/s]\u001b[A\n",
      " 21%|██▏       | 88911/414113 [00:20<01:14, 4341.51it/s]\u001b[A\n",
      " 22%|██▏       | 89359/414113 [00:20<01:14, 4381.50it/s]\u001b[A\n",
      " 22%|██▏       | 89804/414113 [00:21<01:13, 4399.82it/s]\u001b[A\n",
      " 22%|██▏       | 90250/414113 [00:21<01:13, 4417.30it/s]\u001b[A\n",
      " 22%|██▏       | 90692/414113 [00:21<01:13, 4413.41it/s]\u001b[A\n",
      " 22%|██▏       | 91135/414113 [00:21<01:13, 4415.00it/s]\u001b[A\n",
      " 22%|██▏       | 91584/414113 [00:21<01:12, 4436.20it/s]\u001b[A\n",
      " 22%|██▏       | 92031/414113 [00:21<01:12, 4445.93it/s]\u001b[A\n",
      " 22%|██▏       | 92476/414113 [00:21<01:12, 4438.84it/s]\u001b[A\n",
      " 22%|██▏       | 92920/414113 [00:21<01:12, 4404.54it/s]\u001b[A\n",
      " 23%|██▎       | 93361/414113 [00:21<01:12, 4402.09it/s]\u001b[A\n",
      " 23%|██▎       | 93802/414113 [00:21<01:12, 4390.00it/s]\u001b[A\n",
      " 23%|██▎       | 94242/414113 [00:22<01:13, 4346.79it/s]\u001b[A\n",
      " 23%|██▎       | 94677/414113 [00:22<01:13, 4328.72it/s]\u001b[A\n",
      " 23%|██▎       | 95110/414113 [00:22<01:14, 4272.71it/s]\u001b[A\n",
      " 23%|██▎       | 95541/414113 [00:22<01:14, 4282.26it/s]\u001b[A\n",
      " 23%|██▎       | 95970/414113 [00:22<01:14, 4246.33it/s]\u001b[A\n",
      " 23%|██▎       | 96395/414113 [00:22<01:15, 4202.07it/s]\u001b[A\n",
      " 23%|██▎       | 96845/414113 [00:22<01:14, 4284.80it/s]\u001b[A\n",
      " 23%|██▎       | 97280/414113 [00:22<01:13, 4302.27it/s]\u001b[A\n",
      " 24%|██▎       | 97718/414113 [00:22<01:13, 4321.41it/s]\u001b[A\n",
      " 24%|██▎       | 98151/414113 [00:22<01:13, 4288.54it/s]\u001b[A\n",
      " 24%|██▍       | 98581/414113 [00:23<01:13, 4289.15it/s]\u001b[A\n",
      " 24%|██▍       | 99022/414113 [00:23<01:12, 4322.49it/s]\u001b[A\n",
      " 24%|██▍       | 99455/414113 [00:23<01:12, 4317.57it/s]\u001b[A\n",
      " 24%|██▍       | 99905/414113 [00:23<01:11, 4368.36it/s]\u001b[A\n",
      " 24%|██▍       | 100343/414113 [00:23<01:12, 4338.00it/s]\u001b[A\n",
      " 24%|██▍       | 100778/414113 [00:23<01:12, 4338.19it/s]\u001b[A\n",
      " 24%|██▍       | 101212/414113 [00:23<01:12, 4334.40it/s]\u001b[A\n",
      " 25%|██▍       | 101646/414113 [00:23<01:12, 4321.12it/s]\u001b[A\n",
      " 25%|██▍       | 102085/414113 [00:23<01:11, 4339.09it/s]\u001b[A\n",
      " 25%|██▍       | 102530/414113 [00:23<01:11, 4370.96it/s]\u001b[A\n",
      " 25%|██▍       | 102981/414113 [00:24<01:10, 4409.99it/s]\u001b[A\n",
      " 25%|██▍       | 103429/414113 [00:24<01:10, 4430.41it/s]\u001b[A\n",
      " 25%|██▌       | 103873/414113 [00:24<01:10, 4422.03it/s]\u001b[A\n",
      " 25%|██▌       | 104316/414113 [00:24<01:10, 4421.94it/s]\u001b[A\n",
      " 25%|██▌       | 104759/414113 [00:24<01:10, 4413.22it/s]\u001b[A\n",
      " 25%|██▌       | 105201/414113 [00:24<01:10, 4353.49it/s]\u001b[A\n",
      " 26%|██▌       | 105647/414113 [00:24<01:10, 4383.27it/s]\u001b[A\n",
      " 26%|██▌       | 106089/414113 [00:24<01:10, 4392.42it/s]\u001b[A\n",
      " 26%|██▌       | 106529/414113 [00:24<01:11, 4308.71it/s]\u001b[A\n",
      " 26%|██▌       | 106961/414113 [00:25<01:11, 4293.08it/s]\u001b[A\n",
      " 26%|██▌       | 107391/414113 [00:25<01:11, 4266.51it/s]\u001b[A\n",
      " 26%|██▌       | 107818/414113 [00:25<01:12, 4240.18it/s]\u001b[A\n",
      " 26%|██▌       | 108257/414113 [00:25<01:11, 4281.64it/s]\u001b[A\n",
      " 26%|██▌       | 108686/414113 [00:25<01:11, 4281.79it/s]\u001b[A\n",
      " 26%|██▋       | 109115/414113 [00:25<01:11, 4265.70it/s]\u001b[A\n",
      " 26%|██▋       | 109542/414113 [00:25<01:11, 4249.99it/s]\u001b[A\n",
      " 27%|██▋       | 109984/414113 [00:25<01:10, 4299.37it/s]\u001b[A\n",
      " 27%|██▋       | 110417/414113 [00:25<01:10, 4306.43it/s]\u001b[A\n",
      " 27%|██▋       | 110856/414113 [00:25<01:10, 4329.30it/s]\u001b[A\n",
      " 27%|██▋       | 111294/414113 [00:26<01:09, 4342.28it/s]\u001b[A\n",
      " 27%|██▋       | 111737/414113 [00:26<01:09, 4365.96it/s]\u001b[A\n",
      " 27%|██▋       | 112174/414113 [00:26<01:09, 4366.31it/s]\u001b[A\n",
      " 27%|██▋       | 112616/414113 [00:26<01:08, 4381.94it/s]\u001b[A\n",
      " 27%|██▋       | 113055/414113 [00:26<01:09, 4355.30it/s]\u001b[A\n",
      " 27%|██▋       | 113491/414113 [00:26<01:09, 4327.11it/s]\u001b[A\n",
      " 28%|██▊       | 113931/414113 [00:26<01:09, 4346.66it/s]\u001b[A\n",
      " 28%|██▊       | 114366/414113 [00:26<01:09, 4342.99it/s]\u001b[A\n",
      " 28%|██▊       | 114801/414113 [00:26<01:09, 4318.16it/s]\u001b[A\n",
      " 28%|██▊       | 115233/414113 [00:26<01:09, 4270.19it/s]\u001b[A\n",
      " 28%|██▊       | 115661/414113 [00:27<01:10, 4227.43it/s]\u001b[A\n",
      " 28%|██▊       | 116084/414113 [00:27<01:11, 4183.65it/s]\u001b[A\n",
      " 28%|██▊       | 116503/414113 [00:27<01:11, 4157.59it/s]\u001b[A\n",
      " 28%|██▊       | 116919/414113 [00:27<01:12, 4119.32it/s]\u001b[A\n",
      " 28%|██▊       | 117332/414113 [00:27<01:13, 4057.29it/s]\u001b[A\n",
      " 28%|██▊       | 117748/414113 [00:27<01:12, 4086.41it/s]\u001b[A\n",
      " 29%|██▊       | 118175/414113 [00:27<01:11, 4139.37it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 118606/414113 [00:27<01:10, 4187.26it/s]\u001b[A\n",
      " 29%|██▊       | 119044/414113 [00:27<01:09, 4242.65it/s]\u001b[A\n",
      " 29%|██▉       | 119469/414113 [00:27<01:09, 4230.73it/s]\u001b[A\n",
      " 29%|██▉       | 119899/414113 [00:28<01:09, 4250.17it/s]\u001b[A\n",
      " 29%|██▉       | 120332/414113 [00:28<01:08, 4273.42it/s]\u001b[A\n",
      " 29%|██▉       | 120773/414113 [00:28<01:08, 4310.21it/s]\u001b[A\n",
      " 29%|██▉       | 121216/414113 [00:28<01:07, 4342.69it/s]\u001b[A\n",
      " 29%|██▉       | 121655/414113 [00:28<01:07, 4354.67it/s]\u001b[A\n",
      " 29%|██▉       | 122095/414113 [00:28<01:06, 4367.94it/s]\u001b[A\n",
      " 30%|██▉       | 122532/414113 [00:28<01:07, 4325.56it/s]\u001b[A\n",
      " 30%|██▉       | 122966/414113 [00:28<01:07, 4327.45it/s]\u001b[A\n",
      " 30%|██▉       | 123399/414113 [00:28<01:07, 4300.85it/s]\u001b[A\n",
      " 30%|██▉       | 123847/414113 [00:28<01:06, 4351.37it/s]\u001b[A\n",
      " 30%|███       | 124283/414113 [00:29<01:07, 4310.27it/s]\u001b[A\n",
      " 30%|███       | 124715/414113 [00:29<01:07, 4286.14it/s]\u001b[A\n",
      " 30%|███       | 125149/414113 [00:29<01:07, 4300.19it/s]\u001b[A\n",
      " 30%|███       | 125580/414113 [00:29<01:07, 4257.67it/s]\u001b[A\n",
      " 30%|███       | 126015/414113 [00:29<01:07, 4283.55it/s]\u001b[A\n",
      " 31%|███       | 126444/414113 [00:29<01:07, 4267.15it/s]\u001b[A\n",
      " 31%|███       | 126891/414113 [00:29<01:06, 4323.86it/s]\u001b[A\n",
      " 31%|███       | 127328/414113 [00:29<01:06, 4336.10it/s]\u001b[A\n",
      " 31%|███       | 127770/414113 [00:29<01:05, 4356.81it/s]\u001b[A\n",
      " 31%|███       | 128206/414113 [00:29<01:05, 4345.30it/s]\u001b[A\n",
      " 31%|███       | 128641/414113 [00:30<01:06, 4294.17it/s]\u001b[A\n",
      " 31%|███       | 129085/414113 [00:30<01:05, 4334.31it/s]\u001b[A\n",
      " 31%|███▏      | 129519/414113 [00:30<01:06, 4270.97it/s]\u001b[A\n",
      " 31%|███▏      | 129947/414113 [00:30<01:06, 4252.66it/s]\u001b[A\n",
      " 31%|███▏      | 130373/414113 [00:30<01:07, 4225.36it/s]\u001b[A\n",
      " 32%|███▏      | 130796/414113 [00:30<01:07, 4207.25it/s]\u001b[A\n",
      " 32%|███▏      | 131239/414113 [00:30<01:06, 4271.10it/s]\u001b[A\n",
      " 32%|███▏      | 131677/414113 [00:30<01:05, 4302.65it/s]\u001b[A\n",
      " 32%|███▏      | 132112/414113 [00:30<01:05, 4316.59it/s]\u001b[A\n",
      " 32%|███▏      | 132544/414113 [00:30<01:05, 4300.21it/s]\u001b[A\n",
      " 32%|███▏      | 132975/414113 [00:31<01:07, 4165.90it/s]\u001b[A\n",
      " 32%|███▏      | 133393/414113 [00:31<01:07, 4145.90it/s]\u001b[A\n",
      " 32%|███▏      | 133809/414113 [00:31<01:08, 4110.83it/s]\u001b[A\n",
      " 32%|███▏      | 134221/414113 [00:31<01:08, 4094.93it/s]\u001b[A\n",
      " 33%|███▎      | 134648/414113 [00:31<01:07, 4144.47it/s]\u001b[A\n",
      " 33%|███▎      | 135084/414113 [00:31<01:06, 4204.94it/s]\u001b[A\n",
      " 33%|███▎      | 135506/414113 [00:31<01:17, 3605.00it/s]\u001b[A\n",
      " 33%|███▎      | 135927/414113 [00:31<01:13, 3766.26it/s]\u001b[A\n",
      " 33%|███▎      | 136317/414113 [00:31<01:16, 3620.03it/s]\u001b[A\n",
      " 33%|███▎      | 136744/414113 [00:32<01:13, 3791.74it/s]\u001b[A\n",
      " 33%|███▎      | 137172/414113 [00:32<01:10, 3924.11it/s]\u001b[A\n",
      " 33%|███▎      | 137597/414113 [00:32<01:08, 4014.73it/s]\u001b[A\n",
      " 33%|███▎      | 138038/414113 [00:32<01:06, 4123.11it/s]\u001b[A\n",
      " 33%|███▎      | 138467/414113 [00:32<01:06, 4170.32it/s]\u001b[A\n",
      " 34%|███▎      | 138905/414113 [00:32<01:05, 4230.53it/s]\u001b[A\n",
      " 34%|███▎      | 139342/414113 [00:32<01:04, 4269.44it/s]\u001b[A\n",
      " 34%|███▍      | 139779/414113 [00:32<01:03, 4298.03it/s]\u001b[A\n",
      " 34%|███▍      | 140211/414113 [00:32<01:04, 4256.03it/s]\u001b[A\n",
      " 34%|███▍      | 140638/414113 [00:32<01:05, 4200.54it/s]\u001b[A\n",
      " 34%|███▍      | 141060/414113 [00:33<01:04, 4205.97it/s]\u001b[A\n",
      " 34%|███▍      | 141482/414113 [00:33<01:04, 4206.60it/s]\u001b[A\n",
      " 34%|███▍      | 141909/414113 [00:33<01:04, 4224.94it/s]\u001b[A\n",
      " 34%|███▍      | 142337/414113 [00:33<01:04, 4240.72it/s]\u001b[A\n",
      " 34%|███▍      | 142770/414113 [00:33<01:03, 4266.42it/s]\u001b[A\n",
      " 35%|███▍      | 143203/414113 [00:33<01:03, 4284.10it/s]\u001b[A\n",
      " 35%|███▍      | 143643/414113 [00:33<01:02, 4316.31it/s]\u001b[A\n",
      " 35%|███▍      | 144075/414113 [00:33<01:03, 4275.14it/s]\u001b[A\n",
      " 35%|███▍      | 144506/414113 [00:33<01:02, 4284.75it/s]\u001b[A\n",
      " 35%|███▍      | 144935/414113 [00:33<01:03, 4242.79it/s]\u001b[A\n",
      " 35%|███▌      | 145360/414113 [00:34<01:03, 4217.36it/s]\u001b[A\n",
      " 35%|███▌      | 145782/414113 [00:34<01:04, 4187.60it/s]\u001b[A\n",
      " 35%|███▌      | 146201/414113 [00:34<01:04, 4144.89it/s]\u001b[A\n",
      " 35%|███▌      | 146616/414113 [00:34<01:04, 4126.99it/s]\u001b[A\n",
      " 36%|███▌      | 147047/414113 [00:34<01:03, 4178.02it/s]\u001b[A\n",
      " 36%|███▌      | 147466/414113 [00:34<01:03, 4177.14it/s]\u001b[A\n",
      " 36%|███▌      | 147884/414113 [00:34<01:03, 4163.37it/s]\u001b[A\n",
      " 36%|███▌      | 148301/414113 [00:34<01:04, 4150.34it/s]\u001b[A\n",
      " 36%|███▌      | 148738/414113 [00:34<01:02, 4213.58it/s]\u001b[A\n",
      " 36%|███▌      | 149172/414113 [00:34<01:02, 4250.29it/s]\u001b[A\n",
      " 36%|███▌      | 149602/414113 [00:35<01:02, 4262.54it/s]\u001b[A\n",
      " 36%|███▌      | 150033/414113 [00:35<01:01, 4274.77it/s]\u001b[A\n",
      " 36%|███▋      | 150466/414113 [00:35<01:01, 4290.87it/s]\u001b[A\n",
      " 36%|███▋      | 150896/414113 [00:35<01:01, 4288.28it/s]\u001b[A\n",
      " 37%|███▋      | 151334/414113 [00:35<01:00, 4315.37it/s]\u001b[A\n",
      " 37%|███▋      | 151767/414113 [00:35<01:00, 4316.96it/s]\u001b[A\n",
      " 37%|███▋      | 152209/414113 [00:35<01:00, 4345.83it/s]\u001b[A\n",
      " 37%|███▋      | 152644/414113 [00:35<01:01, 4270.39it/s]\u001b[A\n",
      " 37%|███▋      | 153085/414113 [00:35<01:00, 4311.27it/s]\u001b[A\n",
      " 37%|███▋      | 153517/414113 [00:36<01:00, 4287.32it/s]\u001b[A\n",
      " 37%|███▋      | 153947/414113 [00:36<01:01, 4254.06it/s]\u001b[A\n",
      " 37%|███▋      | 154373/414113 [00:36<01:06, 3918.81it/s]\u001b[A\n",
      " 37%|███▋      | 154798/414113 [00:36<01:04, 4011.47it/s]\u001b[A\n",
      " 37%|███▋      | 155236/414113 [00:36<01:02, 4113.88it/s]\u001b[A\n",
      " 38%|███▊      | 155666/414113 [00:36<01:02, 4166.04it/s]\u001b[A\n",
      " 38%|███▊      | 156105/414113 [00:36<01:01, 4228.91it/s]\u001b[A\n",
      " 38%|███▊      | 156538/414113 [00:36<01:00, 4256.71it/s]\u001b[A\n",
      " 38%|███▊      | 156982/414113 [00:36<00:59, 4307.85it/s]\u001b[A\n",
      " 38%|███▊      | 157415/414113 [00:36<00:59, 4287.69it/s]\u001b[A\n",
      " 38%|███▊      | 157868/414113 [00:37<00:58, 4356.00it/s]\u001b[A\n",
      " 38%|███▊      | 158318/414113 [00:37<00:58, 4396.04it/s]\u001b[A\n",
      " 38%|███▊      | 158771/414113 [00:37<00:57, 4433.51it/s]\u001b[A\n",
      " 38%|███▊      | 159228/414113 [00:37<00:57, 4471.37it/s]\u001b[A\n",
      " 39%|███▊      | 159689/414113 [00:37<00:56, 4510.06it/s]\u001b[A\n",
      " 39%|███▊      | 160141/414113 [00:37<00:56, 4505.57it/s]\u001b[A\n",
      " 39%|███▉      | 160592/414113 [00:37<00:56, 4491.35it/s]\u001b[A\n",
      " 39%|███▉      | 161042/414113 [00:37<00:56, 4492.63it/s]\u001b[A\n",
      " 39%|███▉      | 161492/414113 [00:37<00:56, 4460.23it/s]\u001b[A\n",
      " 39%|███▉      | 161943/414113 [00:37<00:56, 4474.15it/s]\u001b[A\n",
      " 39%|███▉      | 162407/414113 [00:38<00:55, 4522.46it/s]\u001b[A\n",
      " 39%|███▉      | 162860/414113 [00:38<00:55, 4487.66it/s]\u001b[A\n",
      " 39%|███▉      | 163309/414113 [00:38<00:56, 4447.83it/s]\u001b[A\n",
      " 40%|███▉      | 163755/414113 [00:38<00:57, 4384.95it/s]\u001b[A\n",
      " 40%|███▉      | 164198/414113 [00:38<00:56, 4397.80it/s]\u001b[A\n",
      " 40%|███▉      | 164643/414113 [00:38<00:56, 4410.48it/s]\u001b[A\n",
      " 40%|███▉      | 165085/414113 [00:38<00:58, 4256.91it/s]\u001b[A\n",
      " 40%|███▉      | 165513/414113 [00:38<00:58, 4262.01it/s]\u001b[A\n",
      " 40%|████      | 165947/414113 [00:38<00:57, 4283.48it/s]\u001b[A\n",
      " 40%|████      | 166377/414113 [00:38<00:58, 4258.82it/s]\u001b[A\n",
      " 40%|████      | 166804/414113 [00:39<00:58, 4228.17it/s]\u001b[A\n",
      " 40%|████      | 167244/414113 [00:39<00:57, 4276.24it/s]\u001b[A\n",
      " 40%|████      | 167675/414113 [00:39<00:57, 4285.42it/s]\u001b[A\n",
      " 41%|████      | 168109/414113 [00:39<00:57, 4301.64it/s]\u001b[A\n",
      " 41%|████      | 168541/414113 [00:39<00:57, 4306.15it/s]\u001b[A\n",
      " 41%|████      | 168972/414113 [00:39<00:57, 4286.51it/s]\u001b[A\n",
      " 41%|████      | 169402/414113 [00:39<00:57, 4289.25it/s]\u001b[A\n",
      " 41%|████      | 169832/414113 [00:39<00:57, 4234.42it/s]\u001b[A\n",
      " 41%|████      | 170256/414113 [00:39<00:58, 4192.44it/s]\u001b[A\n",
      " 41%|████      | 170685/414113 [00:39<00:57, 4219.02it/s]\u001b[A\n",
      " 41%|████▏     | 171108/414113 [00:40<00:57, 4209.50it/s]\u001b[A\n",
      " 41%|████▏     | 171533/414113 [00:40<00:57, 4219.73it/s]\u001b[A\n",
      " 42%|████▏     | 171956/414113 [00:40<00:57, 4205.02it/s]\u001b[A\n",
      " 42%|████▏     | 172377/414113 [00:40<00:57, 4202.95it/s]\u001b[A\n",
      " 42%|████▏     | 172798/414113 [00:40<00:58, 4159.04it/s]\u001b[A\n",
      " 42%|████▏     | 173215/414113 [00:40<00:58, 4107.11it/s]\u001b[A\n",
      " 42%|████▏     | 173634/414113 [00:40<00:58, 4131.08it/s]\u001b[A\n",
      " 42%|████▏     | 174048/414113 [00:41<01:48, 2219.00it/s]\u001b[A\n",
      " 42%|████▏     | 174461/414113 [00:41<01:33, 2576.47it/s]\u001b[A\n",
      " 42%|████▏     | 174870/414113 [00:41<01:22, 2896.85it/s]\u001b[A\n",
      " 42%|████▏     | 175268/414113 [00:41<01:15, 3154.07it/s]\u001b[A\n",
      " 42%|████▏     | 175687/414113 [00:41<01:10, 3404.99it/s]\u001b[A\n",
      " 43%|████▎     | 176076/414113 [00:41<01:08, 3484.40it/s]\u001b[A\n",
      " 43%|████▎     | 176491/414113 [00:41<01:04, 3659.08it/s]\u001b[A\n",
      " 43%|████▎     | 176907/414113 [00:41<01:02, 3794.78it/s]\u001b[A\n",
      " 43%|████▎     | 177332/414113 [00:41<01:00, 3919.62it/s]\u001b[A\n",
      " 43%|████▎     | 177762/414113 [00:41<00:58, 4024.58it/s]\u001b[A\n",
      " 43%|████▎     | 178203/414113 [00:42<00:57, 4132.66it/s]\u001b[A\n",
      " 43%|████▎     | 178625/414113 [00:42<00:56, 4153.79it/s]\u001b[A\n",
      " 43%|████▎     | 179048/414113 [00:42<00:56, 4176.06it/s]\u001b[A\n",
      " 43%|████▎     | 179491/414113 [00:42<00:55, 4246.72it/s]\u001b[A\n",
      " 43%|████▎     | 179935/414113 [00:42<00:54, 4302.80it/s]\u001b[A\n",
      " 44%|████▎     | 180368/414113 [00:42<00:55, 4246.36it/s]\u001b[A\n",
      " 44%|████▎     | 180802/414113 [00:42<00:54, 4273.05it/s]\u001b[A\n",
      " 44%|████▍     | 181232/414113 [00:42<00:54, 4279.44it/s]\u001b[A\n",
      " 44%|████▍     | 181672/414113 [00:42<00:53, 4312.59it/s]\u001b[A\n",
      " 44%|████▍     | 182104/414113 [00:43<00:54, 4249.23it/s]\u001b[A\n",
      " 44%|████▍     | 182530/414113 [00:43<00:54, 4242.92it/s]\u001b[A\n",
      " 44%|████▍     | 182955/414113 [00:43<00:54, 4205.69it/s]\u001b[A\n",
      " 44%|████▍     | 183384/414113 [00:43<00:54, 4230.32it/s]\u001b[A\n",
      " 44%|████▍     | 183810/414113 [00:43<00:54, 4238.54it/s]\u001b[A\n",
      " 44%|████▍     | 184239/414113 [00:43<00:54, 4253.19it/s]\u001b[A\n",
      " 45%|████▍     | 184668/414113 [00:43<00:53, 4263.08it/s]\u001b[A\n",
      " 45%|████▍     | 185095/414113 [00:43<00:53, 4246.00it/s]\u001b[A\n",
      " 45%|████▍     | 185520/414113 [00:43<00:54, 4213.48it/s]\u001b[A\n",
      " 45%|████▍     | 185950/414113 [00:43<00:53, 4238.44it/s]\u001b[A\n",
      " 45%|████▌     | 186384/414113 [00:44<00:53, 4266.40it/s]\u001b[A\n",
      " 45%|████▌     | 186825/414113 [00:44<00:52, 4307.20it/s]\u001b[A\n",
      " 45%|████▌     | 187257/414113 [00:44<00:52, 4308.26it/s]\u001b[A\n",
      " 45%|████▌     | 187688/414113 [00:44<00:52, 4304.84it/s]\u001b[A\n",
      " 45%|████▌     | 188119/414113 [00:44<00:52, 4292.04it/s]\u001b[A\n",
      " 46%|████▌     | 188549/414113 [00:44<00:52, 4288.50it/s]\u001b[A\n",
      " 46%|████▌     | 188978/414113 [00:44<00:52, 4275.96it/s]\u001b[A\n",
      " 46%|████▌     | 189415/414113 [00:44<00:52, 4303.19it/s]\u001b[A\n",
      " 46%|████▌     | 189846/414113 [00:44<00:52, 4263.35it/s]\u001b[A\n",
      " 46%|████▌     | 190273/414113 [00:44<00:53, 4218.73it/s]\u001b[A\n",
      " 46%|████▌     | 190702/414113 [00:45<00:52, 4238.53it/s]\u001b[A\n",
      " 46%|████▌     | 191134/414113 [00:45<00:52, 4262.23it/s]\u001b[A\n",
      " 46%|████▋     | 191566/414113 [00:45<00:52, 4276.11it/s]\u001b[A\n",
      " 46%|████▋     | 191996/414113 [00:45<00:51, 4280.85it/s]\u001b[A\n",
      " 46%|████▋     | 192436/414113 [00:45<00:51, 4313.04it/s]\u001b[A\n",
      " 47%|████▋     | 192868/414113 [00:45<00:51, 4290.77it/s]\u001b[A\n",
      " 47%|████▋     | 193298/414113 [00:45<00:51, 4248.07it/s]\u001b[A\n",
      " 47%|████▋     | 193736/414113 [00:45<00:51, 4286.30it/s]\u001b[A\n",
      " 47%|████▋     | 194166/414113 [00:45<00:51, 4288.50it/s]\u001b[A\n",
      " 47%|████▋     | 194595/414113 [00:45<00:51, 4276.68it/s]\u001b[A\n",
      " 47%|████▋     | 195030/414113 [00:46<00:50, 4298.18it/s]\u001b[A\n",
      " 47%|████▋     | 195460/414113 [00:46<00:50, 4296.78it/s]\u001b[A\n",
      " 47%|████▋     | 195890/414113 [00:46<00:50, 4282.30it/s]\u001b[A\n",
      " 47%|████▋     | 196319/414113 [00:46<00:50, 4279.12it/s]\u001b[A\n",
      " 48%|████▊     | 196747/414113 [00:46<00:51, 4246.01it/s]\u001b[A\n",
      " 48%|████▊     | 197175/414113 [00:46<00:50, 4254.22it/s]\u001b[A\n",
      " 48%|████▊     | 197615/414113 [00:46<00:50, 4295.03it/s]\u001b[A\n",
      " 48%|████▊     | 198052/414113 [00:46<00:50, 4315.45it/s]\u001b[A\n",
      " 48%|████▊     | 198484/414113 [00:46<00:50, 4247.10it/s]\u001b[A\n",
      " 48%|████▊     | 198910/414113 [00:46<00:56, 3831.22it/s]\u001b[A\n",
      " 48%|████▊     | 199328/414113 [00:47<00:54, 3928.21it/s]\u001b[A\n",
      " 48%|████▊     | 199729/414113 [00:47<00:54, 3950.38it/s]\u001b[A\n",
      " 48%|████▊     | 200129/414113 [00:47<00:54, 3959.33it/s]\u001b[A\n",
      " 48%|████▊     | 200540/414113 [00:47<00:53, 4001.07it/s]\u001b[A\n",
      " 49%|████▊     | 200947/414113 [00:47<00:53, 4019.01it/s]\u001b[A\n",
      " 49%|████▊     | 201358/414113 [00:47<00:52, 4045.58it/s]\u001b[A\n",
      " 49%|████▊     | 201782/414113 [00:47<00:51, 4101.58it/s]\u001b[A\n",
      " 49%|████▉     | 202216/414113 [00:47<00:50, 4170.29it/s]\u001b[A\n",
      " 49%|████▉     | 202635/414113 [00:47<00:51, 4131.84it/s]\u001b[A\n",
      " 49%|████▉     | 203071/414113 [00:47<00:50, 4197.58it/s]\u001b[A\n",
      " 49%|████▉     | 203502/414113 [00:48<00:49, 4229.99it/s]\u001b[A\n",
      " 49%|████▉     | 203927/414113 [00:48<00:49, 4234.63it/s]\u001b[A\n",
      " 49%|████▉     | 204368/414113 [00:48<00:48, 4285.14it/s]\u001b[A\n",
      " 49%|████▉     | 204803/414113 [00:48<00:48, 4303.25it/s]\u001b[A\n",
      " 50%|████▉     | 205234/414113 [00:48<00:48, 4292.02it/s]\u001b[A\n",
      " 50%|████▉     | 205669/414113 [00:48<00:48, 4308.24it/s]\u001b[A\n",
      " 50%|████▉     | 206101/414113 [00:48<00:48, 4306.61it/s]\u001b[A\n",
      " 50%|████▉     | 206533/414113 [00:48<00:48, 4307.20it/s]\u001b[A\n",
      " 50%|████▉     | 206964/414113 [00:48<00:48, 4279.10it/s]\u001b[A\n",
      " 50%|█████     | 207394/414113 [00:48<00:48, 4283.54it/s]\u001b[A\n",
      " 50%|█████     | 207823/414113 [00:49<00:48, 4280.93it/s]\u001b[A\n",
      " 50%|█████     | 208258/414113 [00:49<00:47, 4299.53it/s]\u001b[A\n",
      " 50%|█████     | 208696/414113 [00:49<00:47, 4322.20it/s]\u001b[A\n",
      " 51%|█████     | 209129/414113 [00:49<00:47, 4294.42it/s]\u001b[A\n",
      " 51%|█████     | 209567/414113 [00:49<00:47, 4317.42it/s]\u001b[A\n",
      " 51%|█████     | 210000/414113 [00:49<00:47, 4321.14it/s]\u001b[A\n",
      " 51%|█████     | 210434/414113 [00:49<00:47, 4324.54it/s]\u001b[A\n",
      " 51%|█████     | 210867/414113 [00:49<00:47, 4280.57it/s]\u001b[A\n",
      " 51%|█████     | 211296/414113 [00:49<00:47, 4267.58it/s]\u001b[A\n",
      " 51%|█████     | 211732/414113 [00:49<00:47, 4292.89it/s]\u001b[A\n",
      " 51%|█████     | 212174/414113 [00:50<00:46, 4328.01it/s]\u001b[A\n",
      " 51%|█████▏    | 212607/414113 [00:50<00:46, 4320.03it/s]\u001b[A\n",
      " 51%|█████▏    | 213053/414113 [00:50<00:46, 4359.77it/s]\u001b[A\n",
      " 52%|█████▏    | 213490/414113 [00:50<00:46, 4344.94it/s]\u001b[A\n",
      " 52%|█████▏    | 213931/414113 [00:50<00:45, 4363.11it/s]\u001b[A\n",
      " 52%|█████▏    | 214368/414113 [00:50<00:45, 4361.55it/s]\u001b[A\n",
      " 52%|█████▏    | 214805/414113 [00:50<00:45, 4338.20it/s]\u001b[A\n",
      " 52%|█████▏    | 215243/414113 [00:50<00:45, 4349.62it/s]\u001b[A\n",
      " 52%|█████▏    | 215679/414113 [00:50<00:46, 4296.53it/s]\u001b[A\n",
      " 52%|█████▏    | 216113/414113 [00:51<00:45, 4309.15it/s]\u001b[A\n",
      " 52%|█████▏    | 216545/414113 [00:51<00:45, 4304.38it/s]\u001b[A\n",
      " 52%|█████▏    | 216978/414113 [00:51<00:45, 4310.88it/s]\u001b[A\n",
      " 53%|█████▎    | 217413/414113 [00:51<00:45, 4319.18it/s]\u001b[A\n",
      " 53%|█████▎    | 217853/414113 [00:51<00:45, 4342.84it/s]\u001b[A\n",
      " 53%|█████▎    | 218288/414113 [00:51<00:45, 4333.35it/s]\u001b[A\n",
      " 53%|█████▎    | 218730/414113 [00:51<00:44, 4358.65it/s]\u001b[A\n",
      " 53%|█████▎    | 219166/414113 [00:51<00:44, 4351.48it/s]\u001b[A\n",
      " 53%|█████▎    | 219606/414113 [00:51<00:44, 4362.83it/s]\u001b[A\n",
      " 53%|█████▎    | 220043/414113 [00:51<00:44, 4352.98it/s]\u001b[A\n",
      " 53%|█████▎    | 220479/414113 [00:52<00:45, 4290.67it/s]\u001b[A\n",
      " 53%|█████▎    | 220909/414113 [00:52<00:46, 4197.41it/s]\u001b[A\n",
      " 53%|█████▎    | 221330/414113 [00:52<00:46, 4172.83it/s]\u001b[A\n",
      " 54%|█████▎    | 221763/414113 [00:52<00:45, 4217.67it/s]\u001b[A\n",
      " 54%|█████▎    | 222208/414113 [00:52<00:44, 4283.07it/s]\u001b[A\n",
      " 54%|█████▍    | 222652/414113 [00:52<00:44, 4328.26it/s]\u001b[A\n",
      " 54%|█████▍    | 223086/414113 [00:52<00:44, 4329.81it/s]\u001b[A\n",
      " 54%|█████▍    | 223521/414113 [00:52<00:43, 4333.16it/s]\u001b[A\n",
      " 54%|█████▍    | 223955/414113 [00:52<00:43, 4333.59it/s]\u001b[A\n",
      " 54%|█████▍    | 224389/414113 [00:52<00:43, 4332.04it/s]\u001b[A\n",
      " 54%|█████▍    | 224823/414113 [00:53<00:43, 4319.84it/s]\u001b[A\n",
      " 54%|█████▍    | 225262/414113 [00:53<00:43, 4338.76it/s]\u001b[A\n",
      " 55%|█████▍    | 225699/414113 [00:53<00:43, 4345.87it/s]\u001b[A\n",
      " 55%|█████▍    | 226134/414113 [00:53<00:43, 4296.70it/s]\u001b[A\n",
      " 55%|█████▍    | 226590/414113 [00:53<00:42, 4371.23it/s]\u001b[A\n",
      " 55%|█████▍    | 227028/414113 [00:53<00:42, 4368.14it/s]\u001b[A\n",
      " 55%|█████▍    | 227466/414113 [00:53<00:42, 4367.54it/s]\u001b[A\n",
      " 55%|█████▌    | 227911/414113 [00:53<00:42, 4391.58it/s]\u001b[A\n",
      " 55%|█████▌    | 228353/414113 [00:53<00:42, 4398.40it/s]\u001b[A\n",
      " 55%|█████▌    | 228793/414113 [00:53<00:42, 4356.59it/s]\u001b[A\n",
      " 55%|█████▌    | 229229/414113 [00:54<00:42, 4322.26it/s]\u001b[A\n",
      " 55%|█████▌    | 229662/414113 [00:54<00:42, 4303.11it/s]\u001b[A\n",
      " 56%|█████▌    | 230093/414113 [00:54<00:42, 4281.64it/s]\u001b[A\n",
      " 56%|█████▌    | 230522/414113 [00:54<00:43, 4267.75it/s]\u001b[A\n",
      " 56%|█████▌    | 230950/414113 [00:54<00:42, 4269.93it/s]\u001b[A\n",
      " 56%|█████▌    | 231378/414113 [00:54<00:43, 4237.45it/s]\u001b[A\n",
      " 56%|█████▌    | 231802/414113 [00:54<00:43, 4230.49it/s]\u001b[A\n",
      " 56%|█████▌    | 232226/414113 [00:54<00:43, 4189.65it/s]\u001b[A\n",
      " 56%|█████▌    | 232646/414113 [00:54<00:43, 4157.08it/s]\u001b[A\n",
      " 56%|█████▋    | 233071/414113 [00:54<00:43, 4184.00it/s]\u001b[A\n",
      " 56%|█████▋    | 233491/414113 [00:55<00:43, 4187.78it/s]\u001b[A\n",
      " 56%|█████▋    | 233923/414113 [00:55<00:42, 4226.41it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 234358/414113 [00:55<00:42, 4261.55it/s]\u001b[A\n",
      " 57%|█████▋    | 234785/414113 [00:55<00:42, 4248.93it/s]\u001b[A\n",
      " 57%|█████▋    | 235228/414113 [00:55<00:41, 4300.69it/s]\u001b[A\n",
      " 57%|█████▋    | 235659/414113 [00:55<00:41, 4279.82it/s]\u001b[A\n",
      " 57%|█████▋    | 236097/414113 [00:55<00:41, 4306.72it/s]\u001b[A\n",
      " 57%|█████▋    | 236528/414113 [00:55<00:41, 4261.23it/s]\u001b[A\n",
      " 57%|█████▋    | 236955/414113 [00:55<00:41, 4248.09it/s]\u001b[A\n",
      " 57%|█████▋    | 237380/414113 [00:55<00:41, 4220.70it/s]\u001b[A\n",
      " 57%|█████▋    | 237803/414113 [00:56<00:42, 4180.29it/s]\u001b[A\n",
      " 58%|█████▊    | 238230/414113 [00:56<00:41, 4205.26it/s]\u001b[A\n",
      " 58%|█████▊    | 238651/414113 [00:56<00:42, 4173.26it/s]\u001b[A\n",
      " 58%|█████▊    | 239077/414113 [00:56<00:41, 4196.67it/s]\u001b[A\n",
      " 58%|█████▊    | 239497/414113 [00:56<00:41, 4193.75it/s]\u001b[A\n",
      " 58%|█████▊    | 239917/414113 [00:56<00:41, 4176.36it/s]\u001b[A\n",
      " 58%|█████▊    | 240335/414113 [00:56<00:41, 4159.11it/s]\u001b[A\n",
      " 58%|█████▊    | 240751/414113 [00:56<00:42, 4124.22it/s]\u001b[A\n",
      " 58%|█████▊    | 241164/414113 [00:56<00:42, 4062.88it/s]\u001b[A\n",
      " 58%|█████▊    | 241581/414113 [00:56<00:42, 4092.21it/s]\u001b[A\n",
      " 58%|█████▊    | 241997/414113 [00:57<00:41, 4110.99it/s]\u001b[A\n",
      " 59%|█████▊    | 242421/414113 [00:57<00:41, 4147.77it/s]\u001b[A\n",
      " 59%|█████▊    | 242849/414113 [00:57<00:40, 4185.20it/s]\u001b[A\n",
      " 59%|█████▊    | 243268/414113 [00:57<00:41, 4140.24it/s]\u001b[A\n",
      " 59%|█████▉    | 243706/414113 [00:57<00:40, 4207.20it/s]\u001b[A\n",
      " 59%|█████▉    | 244133/414113 [00:57<00:40, 4223.89it/s]\u001b[A\n",
      " 59%|█████▉    | 244556/414113 [00:57<00:40, 4220.59it/s]\u001b[A\n",
      " 59%|█████▉    | 244989/414113 [00:57<00:39, 4252.20it/s]\u001b[A\n",
      " 59%|█████▉    | 245418/414113 [00:57<00:39, 4260.46it/s]\u001b[A\n",
      " 59%|█████▉    | 245845/414113 [00:57<00:39, 4247.32it/s]\u001b[A\n",
      " 59%|█████▉    | 246277/414113 [00:58<00:39, 4267.03it/s]\u001b[A\n",
      " 60%|█████▉    | 246704/414113 [00:58<00:39, 4234.48it/s]\u001b[A\n",
      " 60%|█████▉    | 247135/414113 [00:58<00:39, 4254.72it/s]\u001b[A\n",
      " 60%|█████▉    | 247568/414113 [00:58<00:38, 4276.81it/s]\u001b[A\n",
      " 60%|█████▉    | 247998/414113 [00:58<00:38, 4281.28it/s]\u001b[A\n",
      " 60%|█████▉    | 248427/414113 [00:58<00:38, 4255.53it/s]\u001b[A\n",
      " 60%|██████    | 248853/414113 [00:58<00:39, 4209.65it/s]\u001b[A\n",
      " 60%|██████    | 249281/414113 [00:58<00:38, 4228.84it/s]\u001b[A\n",
      " 60%|██████    | 249714/414113 [00:58<00:38, 4256.27it/s]\u001b[A\n",
      " 60%|██████    | 250140/414113 [00:58<00:38, 4245.06it/s]\u001b[A\n",
      " 61%|██████    | 250565/414113 [00:59<00:38, 4242.23it/s]\u001b[A\n",
      " 61%|██████    | 250990/414113 [00:59<00:38, 4234.81it/s]\u001b[A\n",
      " 61%|██████    | 251415/414113 [00:59<00:38, 4236.70it/s]\u001b[A\n",
      " 61%|██████    | 251855/414113 [00:59<00:37, 4284.38it/s]\u001b[A\n",
      " 61%|██████    | 252295/414113 [00:59<00:37, 4317.88it/s]\u001b[A\n",
      " 61%|██████    | 252727/414113 [00:59<00:37, 4309.00it/s]\u001b[A\n",
      " 61%|██████    | 253159/414113 [00:59<00:37, 4305.73it/s]\u001b[A\n",
      " 61%|██████    | 253590/414113 [00:59<00:37, 4279.81it/s]\u001b[A\n",
      " 61%|██████▏   | 254022/414113 [00:59<00:37, 4289.14it/s]\u001b[A\n",
      " 61%|██████▏   | 254455/414113 [00:59<00:37, 4299.64it/s]\u001b[A\n",
      " 62%|██████▏   | 254886/414113 [01:00<00:37, 4296.96it/s]\u001b[A\n",
      " 62%|██████▏   | 255318/414113 [01:00<00:36, 4303.51it/s]\u001b[A\n",
      " 62%|██████▏   | 255749/414113 [01:00<00:42, 3755.71it/s]\u001b[A\n",
      " 62%|██████▏   | 256183/414113 [01:00<00:40, 3912.29it/s]\u001b[A\n",
      " 62%|██████▏   | 256619/414113 [01:00<00:39, 4035.65it/s]\u001b[A\n",
      " 62%|██████▏   | 257044/414113 [01:00<00:38, 4096.26it/s]\u001b[A\n",
      " 62%|██████▏   | 257476/414113 [01:00<00:37, 4160.67it/s]\u001b[A\n",
      " 62%|██████▏   | 257914/414113 [01:00<00:36, 4222.36it/s]\u001b[A\n",
      " 62%|██████▏   | 258350/414113 [01:00<00:36, 4262.21it/s]\u001b[A\n",
      " 62%|██████▏   | 258779/414113 [01:01<00:36, 4263.18it/s]\u001b[A\n",
      " 63%|██████▎   | 259208/414113 [01:01<00:36, 4260.00it/s]\u001b[A\n",
      " 63%|██████▎   | 259647/414113 [01:01<00:35, 4294.81it/s]\u001b[A\n",
      " 63%|██████▎   | 260082/414113 [01:01<00:35, 4308.59it/s]\u001b[A\n",
      " 63%|██████▎   | 260523/414113 [01:01<00:35, 4336.26it/s]\u001b[A\n",
      " 63%|██████▎   | 260960/414113 [01:01<00:35, 4344.56it/s]\u001b[A\n",
      " 63%|██████▎   | 261398/414113 [01:01<00:35, 4352.54it/s]\u001b[A\n",
      " 63%|██████▎   | 261834/414113 [01:01<00:35, 4338.80it/s]\u001b[A\n",
      " 63%|██████▎   | 262270/414113 [01:01<00:34, 4344.55it/s]\u001b[A\n",
      " 63%|██████▎   | 262705/414113 [01:01<00:35, 4292.27it/s]\u001b[A\n",
      " 64%|██████▎   | 263135/414113 [01:02<00:35, 4258.98it/s]\u001b[A\n",
      " 64%|██████▎   | 263563/414113 [01:02<00:35, 4262.59it/s]\u001b[A\n",
      " 64%|██████▎   | 263990/414113 [01:02<00:35, 4239.25it/s]\u001b[A\n",
      " 64%|██████▍   | 264418/414113 [01:02<00:35, 4248.35it/s]\u001b[A\n",
      " 64%|██████▍   | 264843/414113 [01:02<00:35, 4248.03it/s]\u001b[A\n",
      " 64%|██████▍   | 265274/414113 [01:02<00:34, 4264.26it/s]\u001b[A\n",
      " 64%|██████▍   | 265715/414113 [01:02<00:34, 4304.84it/s]\u001b[A\n",
      " 64%|██████▍   | 266157/414113 [01:02<00:34, 4336.80it/s]\u001b[A\n",
      " 64%|██████▍   | 266606/414113 [01:02<00:33, 4379.75it/s]\u001b[A\n",
      " 64%|██████▍   | 267045/414113 [01:02<00:33, 4353.63it/s]\u001b[A\n",
      " 65%|██████▍   | 267495/414113 [01:03<00:33, 4394.09it/s]\u001b[A\n",
      " 65%|██████▍   | 267936/414113 [01:03<00:33, 4396.49it/s]\u001b[A\n",
      " 65%|██████▍   | 268384/414113 [01:03<00:32, 4419.16it/s]\u001b[A\n",
      " 65%|██████▍   | 268830/414113 [01:03<00:32, 4431.32it/s]\u001b[A\n",
      " 65%|██████▌   | 269278/414113 [01:03<00:32, 4445.29it/s]\u001b[A\n",
      " 65%|██████▌   | 269729/414113 [01:03<00:32, 4464.25it/s]\u001b[A\n",
      " 65%|██████▌   | 270176/414113 [01:03<00:32, 4463.75it/s]\u001b[A\n",
      " 65%|██████▌   | 270623/414113 [01:03<00:32, 4391.36it/s]\u001b[A\n",
      " 65%|██████▌   | 271063/414113 [01:03<00:33, 4323.89it/s]\u001b[A\n",
      " 66%|██████▌   | 271496/414113 [01:03<00:33, 4310.16it/s]\u001b[A\n",
      " 66%|██████▌   | 271928/414113 [01:04<00:33, 4284.03it/s]\u001b[A\n",
      " 66%|██████▌   | 272357/414113 [01:04<00:33, 4252.44it/s]\u001b[A\n",
      " 66%|██████▌   | 272784/414113 [01:04<00:33, 4256.56it/s]\u001b[A\n",
      " 66%|██████▌   | 273210/414113 [01:04<00:33, 4235.44it/s]\u001b[A\n",
      " 66%|██████▌   | 273636/414113 [01:04<00:33, 4241.55it/s]\u001b[A\n",
      " 66%|██████▌   | 274064/414113 [01:04<00:32, 4250.23it/s]\u001b[A\n",
      " 66%|██████▋   | 274490/414113 [01:04<00:32, 4236.43it/s]\u001b[A\n",
      " 66%|██████▋   | 274916/414113 [01:04<00:32, 4242.70it/s]\u001b[A\n",
      " 66%|██████▋   | 275341/414113 [01:04<00:33, 4095.62it/s]\u001b[A\n",
      " 67%|██████▋   | 275775/414113 [01:04<00:33, 4165.60it/s]\u001b[A\n",
      " 67%|██████▋   | 276205/414113 [01:05<00:32, 4203.41it/s]\u001b[A\n",
      " 67%|██████▋   | 276636/414113 [01:05<00:32, 4232.81it/s]\u001b[A\n",
      " 67%|██████▋   | 277065/414113 [01:05<00:32, 4247.40it/s]\u001b[A\n",
      " 67%|██████▋   | 277491/414113 [01:05<00:32, 4248.04it/s]\u001b[A\n",
      " 67%|██████▋   | 277924/414113 [01:05<00:31, 4271.12it/s]\u001b[A\n",
      " 67%|██████▋   | 278353/414113 [01:05<00:31, 4274.02it/s]\u001b[A\n",
      " 67%|██████▋   | 278781/414113 [01:05<00:31, 4247.94it/s]\u001b[A\n",
      " 67%|██████▋   | 279206/414113 [01:05<00:32, 4141.21it/s]\u001b[A\n",
      " 68%|██████▊   | 279622/414113 [01:05<00:32, 4145.14it/s]\u001b[A\n",
      " 68%|██████▊   | 280061/414113 [01:06<00:31, 4213.93it/s]\u001b[A\n",
      " 68%|██████▊   | 280484/414113 [01:06<00:31, 4190.57it/s]\u001b[A\n",
      " 68%|██████▊   | 280913/414113 [01:06<00:31, 4218.45it/s]\u001b[A\n",
      " 68%|██████▊   | 281346/414113 [01:06<00:31, 4247.80it/s]\u001b[A\n",
      " 68%|██████▊   | 281775/414113 [01:06<00:31, 4258.09it/s]\u001b[A\n",
      " 68%|██████▊   | 282202/414113 [01:06<00:30, 4256.14it/s]\u001b[A\n",
      " 68%|██████▊   | 282653/414113 [01:06<00:30, 4329.23it/s]\u001b[A\n",
      " 68%|██████▊   | 283087/414113 [01:06<00:30, 4308.88it/s]\u001b[A\n",
      " 68%|██████▊   | 283519/414113 [01:06<00:30, 4260.80it/s]\u001b[A\n",
      " 69%|██████▊   | 283946/414113 [01:06<00:30, 4210.62it/s]\u001b[A\n",
      " 69%|██████▊   | 284371/414113 [01:07<00:30, 4221.32it/s]\u001b[A\n",
      " 69%|██████▉   | 284808/414113 [01:07<00:30, 4262.33it/s]\u001b[A\n",
      " 69%|██████▉   | 285246/414113 [01:07<00:30, 4294.77it/s]\u001b[A\n",
      " 69%|██████▉   | 285682/414113 [01:07<00:29, 4312.55it/s]\u001b[A\n",
      " 69%|██████▉   | 286114/414113 [01:07<00:29, 4299.00it/s]\u001b[A\n",
      " 69%|██████▉   | 286545/414113 [01:07<00:29, 4291.48it/s]\u001b[A\n",
      " 69%|██████▉   | 286979/414113 [01:07<00:29, 4304.71it/s]\u001b[A\n",
      " 69%|██████▉   | 287410/414113 [01:07<00:29, 4304.51it/s]\u001b[A\n",
      " 70%|██████▉   | 287846/414113 [01:07<00:29, 4320.73it/s]\u001b[A\n",
      " 70%|██████▉   | 288279/414113 [01:07<00:29, 4305.96it/s]\u001b[A\n",
      " 70%|██████▉   | 288710/414113 [01:08<00:29, 4290.73it/s]\u001b[A\n",
      " 70%|██████▉   | 289140/414113 [01:08<00:29, 4285.64it/s]\u001b[A\n",
      " 70%|██████▉   | 289572/414113 [01:08<00:29, 4293.74it/s]\u001b[A\n",
      " 70%|███████   | 290007/414113 [01:08<00:28, 4307.53it/s]\u001b[A\n",
      " 70%|███████   | 290438/414113 [01:08<00:28, 4281.55it/s]\u001b[A\n",
      " 70%|███████   | 290869/414113 [01:08<00:28, 4287.10it/s]\u001b[A\n",
      " 70%|███████   | 291301/414113 [01:08<00:28, 4296.03it/s]\u001b[A\n",
      " 70%|███████   | 291731/414113 [01:08<00:28, 4295.01it/s]\u001b[A\n",
      " 71%|███████   | 292172/414113 [01:08<00:28, 4326.28it/s]\u001b[A\n",
      " 71%|███████   | 292605/414113 [01:08<00:28, 4275.96it/s]\u001b[A\n",
      " 71%|███████   | 293043/414113 [01:09<00:28, 4306.41it/s]\u001b[A\n",
      " 71%|███████   | 293483/414113 [01:09<00:27, 4333.91it/s]\u001b[A\n",
      " 71%|███████   | 293919/414113 [01:09<00:27, 4339.91it/s]\u001b[A\n",
      " 71%|███████   | 294359/414113 [01:09<00:27, 4355.92it/s]\u001b[A\n",
      " 71%|███████   | 294795/414113 [01:09<00:27, 4316.29it/s]\u001b[A\n",
      " 71%|███████▏  | 295227/414113 [01:09<00:27, 4311.47it/s]\u001b[A\n",
      " 71%|███████▏  | 295659/414113 [01:09<00:27, 4277.62it/s]\u001b[A\n",
      " 71%|███████▏  | 296089/414113 [01:09<00:27, 4283.79it/s]\u001b[A\n",
      " 72%|███████▏  | 296520/414113 [01:09<00:27, 4290.26it/s]\u001b[A\n",
      " 72%|███████▏  | 296950/414113 [01:09<00:27, 4291.11it/s]\u001b[A\n",
      " 72%|███████▏  | 297380/414113 [01:10<00:27, 4266.49it/s]\u001b[A\n",
      " 72%|███████▏  | 297807/414113 [01:10<00:27, 4254.80it/s]\u001b[A\n",
      " 72%|███████▏  | 298237/414113 [01:10<00:27, 4267.72it/s]\u001b[A\n",
      " 72%|███████▏  | 298664/414113 [01:10<00:27, 4264.37it/s]\u001b[A\n",
      " 72%|███████▏  | 299099/414113 [01:10<00:26, 4288.90it/s]\u001b[A\n",
      " 72%|███████▏  | 299529/414113 [01:10<00:26, 4291.03it/s]\u001b[A\n",
      " 72%|███████▏  | 299960/414113 [01:10<00:26, 4294.90it/s]\u001b[A\n",
      " 73%|███████▎  | 300396/414113 [01:10<00:26, 4313.98it/s]\u001b[A\n",
      " 73%|███████▎  | 300828/414113 [01:10<00:26, 4306.95it/s]\u001b[A\n",
      " 73%|███████▎  | 301259/414113 [01:10<00:26, 4298.82it/s]\u001b[A\n",
      " 73%|███████▎  | 301689/414113 [01:11<00:26, 4216.71it/s]\u001b[A\n",
      " 73%|███████▎  | 302112/414113 [01:11<00:26, 4180.45it/s]\u001b[A\n",
      " 73%|███████▎  | 302531/414113 [01:11<00:26, 4137.89it/s]\u001b[A\n",
      " 73%|███████▎  | 302946/414113 [01:11<00:26, 4132.17it/s]\u001b[A\n",
      " 73%|███████▎  | 303387/414113 [01:11<00:26, 4210.68it/s]\u001b[A\n",
      " 73%|███████▎  | 303822/414113 [01:11<00:25, 4249.95it/s]\u001b[A\n",
      " 73%|███████▎  | 304255/414113 [01:11<00:25, 4270.84it/s]\u001b[A\n",
      " 74%|███████▎  | 304686/414113 [01:11<00:25, 4279.83it/s]\u001b[A\n",
      " 74%|███████▎  | 305115/414113 [01:11<00:25, 4244.94it/s]\u001b[A\n",
      " 74%|███████▍  | 305542/414113 [01:11<00:25, 4250.98it/s]\u001b[A\n",
      " 74%|███████▍  | 305968/414113 [01:12<00:25, 4248.45it/s]\u001b[A\n",
      " 74%|███████▍  | 306406/414113 [01:12<00:25, 4286.23it/s]\u001b[A\n",
      " 74%|███████▍  | 306846/414113 [01:12<00:24, 4318.41it/s]\u001b[A\n",
      " 74%|███████▍  | 307296/414113 [01:12<00:24, 4371.23it/s]\u001b[A\n",
      " 74%|███████▍  | 307749/414113 [01:12<00:24, 4416.68it/s]\u001b[A\n",
      " 74%|███████▍  | 308191/414113 [01:12<00:25, 4148.86it/s]\u001b[A\n",
      " 75%|███████▍  | 308610/414113 [01:12<00:25, 4118.24it/s]\u001b[A\n",
      " 75%|███████▍  | 309055/414113 [01:12<00:24, 4209.67it/s]\u001b[A\n",
      " 75%|███████▍  | 309510/414113 [01:12<00:24, 4303.65it/s]\u001b[A\n",
      " 75%|███████▍  | 309953/414113 [01:12<00:23, 4340.37it/s]\u001b[A\n",
      " 75%|███████▍  | 310397/414113 [01:13<00:23, 4369.19it/s]\u001b[A\n",
      " 75%|███████▌  | 310845/414113 [01:13<00:23, 4401.45it/s]\u001b[A\n",
      " 75%|███████▌  | 311293/414113 [01:13<00:23, 4423.68it/s]\u001b[A\n",
      " 75%|███████▌  | 311743/414113 [01:13<00:23, 4444.82it/s]\u001b[A\n",
      " 75%|███████▌  | 312196/414113 [01:13<00:22, 4468.77it/s]\u001b[A\n",
      " 75%|███████▌  | 312645/414113 [01:13<00:22, 4475.03it/s]\u001b[A\n",
      " 76%|███████▌  | 313096/414113 [01:13<00:22, 4482.52it/s]\u001b[A\n",
      " 76%|███████▌  | 313545/414113 [01:13<00:22, 4468.40it/s]\u001b[A\n",
      " 76%|███████▌  | 313992/414113 [01:13<00:22, 4464.12it/s]\u001b[A\n",
      " 76%|███████▌  | 314439/414113 [01:13<00:22, 4436.39it/s]\u001b[A\n",
      " 76%|███████▌  | 314883/414113 [01:14<00:22, 4361.48it/s]\u001b[A\n",
      " 76%|███████▌  | 315320/414113 [01:14<00:22, 4304.32it/s]\u001b[A\n",
      " 76%|███████▋  | 315780/414113 [01:14<00:22, 4386.67it/s]\u001b[A\n",
      " 76%|███████▋  | 316237/414113 [01:14<00:22, 4440.09it/s]\u001b[A\n",
      " 76%|███████▋  | 316691/414113 [01:14<00:21, 4468.54it/s]\u001b[A\n",
      " 77%|███████▋  | 317154/414113 [01:14<00:21, 4514.45it/s]\u001b[A\n",
      " 77%|███████▋  | 317616/414113 [01:14<00:21, 4544.37it/s]\u001b[A\n",
      " 77%|███████▋  | 318071/414113 [01:14<00:21, 4467.23it/s]\u001b[A\n",
      " 77%|███████▋  | 318519/414113 [01:14<00:21, 4444.94it/s]\u001b[A\n",
      " 77%|███████▋  | 318970/414113 [01:15<00:21, 4464.13it/s]\u001b[A\n",
      " 77%|███████▋  | 319417/414113 [01:15<00:21, 4457.29it/s]\u001b[A\n",
      " 77%|███████▋  | 319867/414113 [01:15<00:21, 4469.85it/s]\u001b[A\n",
      " 77%|███████▋  | 320315/414113 [01:15<00:21, 4439.13it/s]\u001b[A\n",
      " 77%|███████▋  | 320760/414113 [01:15<00:21, 4404.78it/s]\u001b[A\n",
      " 78%|███████▊  | 321201/414113 [01:15<00:21, 4388.08it/s]\u001b[A\n",
      " 78%|███████▊  | 321649/414113 [01:15<00:20, 4413.34it/s]\u001b[A\n",
      " 78%|███████▊  | 322101/414113 [01:15<00:20, 4444.15it/s]\u001b[A\n",
      " 78%|███████▊  | 322548/414113 [01:15<00:20, 4449.23it/s]\u001b[A\n",
      " 78%|███████▊  | 323000/414113 [01:15<00:20, 4470.16it/s]\u001b[A\n",
      " 78%|███████▊  | 323459/414113 [01:16<00:20, 4504.58it/s]\u001b[A\n",
      " 78%|███████▊  | 323910/414113 [01:16<00:20, 4415.72it/s]\u001b[A\n",
      " 78%|███████▊  | 324353/414113 [01:16<00:40, 2218.15it/s]\u001b[A\n",
      " 78%|███████▊  | 324794/414113 [01:16<00:34, 2606.58it/s]\u001b[A\n",
      " 79%|███████▊  | 325222/414113 [01:16<00:30, 2952.05it/s]\u001b[A\n",
      " 79%|███████▊  | 325644/414113 [01:16<00:27, 3243.95it/s]\u001b[A\n",
      " 79%|███████▊  | 326042/414113 [01:16<00:25, 3391.54it/s]\u001b[A\n",
      " 79%|███████▉  | 326476/414113 [01:17<00:24, 3628.59it/s]\u001b[A\n",
      " 79%|███████▉  | 326904/414113 [01:17<00:22, 3799.97it/s]\u001b[A\n",
      " 79%|███████▉  | 327334/414113 [01:17<00:22, 3936.04it/s]\u001b[A\n",
      " 79%|███████▉  | 327752/414113 [01:17<00:21, 4005.91it/s]\u001b[A\n",
      " 79%|███████▉  | 328182/414113 [01:17<00:21, 4088.11it/s]\u001b[A\n",
      " 79%|███████▉  | 328607/414113 [01:17<00:20, 4134.03it/s]\u001b[A\n",
      " 79%|███████▉  | 329029/414113 [01:17<00:20, 4157.97it/s]\u001b[A\n",
      " 80%|███████▉  | 329451/414113 [01:17<00:20, 4167.72it/s]\u001b[A\n",
      " 80%|███████▉  | 329881/414113 [01:17<00:20, 4204.32it/s]\u001b[A\n",
      " 80%|███████▉  | 330305/414113 [01:17<00:19, 4204.03it/s]\u001b[A\n",
      " 80%|███████▉  | 330728/414113 [01:18<00:19, 4192.52it/s]\u001b[A\n",
      " 80%|███████▉  | 331149/414113 [01:18<00:20, 4089.44it/s]\u001b[A\n",
      " 80%|████████  | 331567/414113 [01:18<00:20, 4116.12it/s]\u001b[A\n",
      " 80%|████████  | 331991/414113 [01:18<00:19, 4152.36it/s]\u001b[A\n",
      " 80%|████████  | 332408/414113 [01:18<00:19, 4128.10it/s]\u001b[A\n",
      " 80%|████████  | 332822/414113 [01:18<00:19, 4091.97it/s]\u001b[A\n",
      " 80%|████████  | 333254/414113 [01:18<00:19, 4157.13it/s]\u001b[A\n",
      " 81%|████████  | 333672/414113 [01:18<00:19, 4162.65it/s]\u001b[A\n",
      " 81%|████████  | 334089/414113 [01:18<00:19, 4161.85it/s]\u001b[A\n",
      " 81%|████████  | 334517/414113 [01:18<00:18, 4193.22it/s]\u001b[A\n",
      " 81%|████████  | 334937/414113 [01:19<00:18, 4185.58it/s]\u001b[A\n",
      " 81%|████████  | 335356/414113 [01:19<00:18, 4166.52it/s]\u001b[A\n",
      " 81%|████████  | 335780/414113 [01:19<00:18, 4185.12it/s]\u001b[A\n",
      " 81%|████████  | 336199/414113 [01:19<00:18, 4166.29it/s]\u001b[A\n",
      " 81%|████████▏ | 336631/414113 [01:19<00:18, 4208.84it/s]\u001b[A\n",
      " 81%|████████▏ | 337054/414113 [01:19<00:18, 4213.12it/s]\u001b[A\n",
      " 81%|████████▏ | 337479/414113 [01:19<00:18, 4223.07it/s]\u001b[A\n",
      " 82%|████████▏ | 337902/414113 [01:19<00:18, 4209.10it/s]\u001b[A\n",
      " 82%|████████▏ | 338328/414113 [01:19<00:17, 4222.23it/s]\u001b[A\n",
      " 82%|████████▏ | 338751/414113 [01:19<00:17, 4216.24it/s]\u001b[A\n",
      " 82%|████████▏ | 339173/414113 [01:20<00:17, 4200.54it/s]\u001b[A\n",
      " 82%|████████▏ | 339602/414113 [01:20<00:17, 4226.19it/s]\u001b[A\n",
      " 82%|████████▏ | 340025/414113 [01:20<00:17, 4154.48it/s]\u001b[A\n",
      " 82%|████████▏ | 340441/414113 [01:20<00:17, 4096.08it/s]\u001b[A\n",
      " 82%|████████▏ | 340852/414113 [01:20<00:18, 4066.48it/s]\u001b[A\n",
      " 82%|████████▏ | 341270/414113 [01:20<00:17, 4099.44it/s]\u001b[A\n",
      " 83%|████████▎ | 341709/414113 [01:20<00:17, 4181.03it/s]\u001b[A\n",
      " 83%|████████▎ | 342134/414113 [01:20<00:17, 4200.52it/s]\u001b[A\n",
      " 83%|████████▎ | 342565/414113 [01:20<00:16, 4229.95it/s]\u001b[A\n",
      " 83%|████████▎ | 342989/414113 [01:21<00:16, 4223.49it/s]\u001b[A\n",
      " 83%|████████▎ | 343415/414113 [01:21<00:16, 4234.24it/s]\u001b[A\n",
      " 83%|████████▎ | 343839/414113 [01:21<00:16, 4230.00it/s]\u001b[A\n",
      " 83%|████████▎ | 344263/414113 [01:21<00:16, 4223.12it/s]\u001b[A\n",
      " 83%|████████▎ | 344686/414113 [01:21<00:16, 4209.85it/s]\u001b[A\n",
      " 83%|████████▎ | 345115/414113 [01:21<00:16, 4232.45it/s]\u001b[A\n",
      " 83%|████████▎ | 345539/414113 [01:21<00:16, 4230.70it/s]\u001b[A\n",
      " 84%|████████▎ | 345971/414113 [01:21<00:16, 4256.97it/s]\u001b[A\n",
      " 84%|████████▎ | 346397/414113 [01:21<00:15, 4252.36it/s]\u001b[A\n",
      " 84%|████████▍ | 346823/414113 [01:21<00:15, 4219.33it/s]\u001b[A\n",
      " 84%|████████▍ | 347248/414113 [01:22<00:15, 4226.67it/s]\u001b[A\n",
      " 84%|████████▍ | 347671/414113 [01:22<00:15, 4223.05it/s]\u001b[A\n",
      " 84%|████████▍ | 348094/414113 [01:22<00:15, 4189.87it/s]\u001b[A\n",
      " 84%|████████▍ | 348514/414113 [01:22<00:15, 4184.64it/s]\u001b[A\n",
      " 84%|████████▍ | 348933/414113 [01:22<00:15, 4178.25it/s]\u001b[A\n",
      " 84%|████████▍ | 349355/414113 [01:22<00:15, 4188.85it/s]\u001b[A\n",
      " 84%|████████▍ | 349777/414113 [01:22<00:15, 4197.74it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 350202/414113 [01:22<00:15, 4210.97it/s]\u001b[A\n",
      " 85%|████████▍ | 350635/414113 [01:22<00:14, 4245.54it/s]\u001b[A\n",
      " 85%|████████▍ | 351060/414113 [01:22<00:14, 4241.73it/s]\u001b[A\n",
      " 85%|████████▍ | 351487/414113 [01:23<00:14, 4248.85it/s]\u001b[A\n",
      " 85%|████████▍ | 351915/414113 [01:23<00:14, 4256.78it/s]\u001b[A\n",
      " 85%|████████▌ | 352341/414113 [01:23<00:15, 4072.99it/s]\u001b[A\n",
      " 85%|████████▌ | 352772/414113 [01:23<00:14, 4139.68it/s]\u001b[A\n",
      " 85%|████████▌ | 353198/414113 [01:23<00:14, 4173.97it/s]\u001b[A\n",
      " 85%|████████▌ | 353633/414113 [01:23<00:14, 4222.66it/s]\u001b[A\n",
      " 85%|████████▌ | 354057/414113 [01:23<00:14, 4206.80it/s]\u001b[A\n",
      " 86%|████████▌ | 354485/414113 [01:23<00:14, 4227.02it/s]\u001b[A\n",
      " 86%|████████▌ | 354922/414113 [01:23<00:13, 4266.84it/s]\u001b[A\n",
      " 86%|████████▌ | 355350/414113 [01:23<00:13, 4236.12it/s]\u001b[A\n",
      " 86%|████████▌ | 355774/414113 [01:24<00:13, 4207.14it/s]\u001b[A\n",
      " 86%|████████▌ | 356199/414113 [01:24<00:13, 4219.83it/s]\u001b[A\n",
      " 86%|████████▌ | 356622/414113 [01:24<00:13, 4221.92it/s]\u001b[A\n",
      " 86%|████████▌ | 357053/414113 [01:24<00:13, 4246.06it/s]\u001b[A\n",
      " 86%|████████▋ | 357478/414113 [01:24<00:13, 4199.84it/s]\u001b[A\n",
      " 86%|████████▋ | 357916/414113 [01:24<00:13, 4250.38it/s]\u001b[A\n",
      " 87%|████████▋ | 358342/414113 [01:24<00:13, 4228.36it/s]\u001b[A\n",
      " 87%|████████▋ | 358779/414113 [01:24<00:12, 4267.60it/s]\u001b[A\n",
      " 87%|████████▋ | 359207/414113 [01:24<00:12, 4269.29it/s]\u001b[A\n",
      " 87%|████████▋ | 359635/414113 [01:24<00:12, 4252.21it/s]\u001b[A\n",
      " 87%|████████▋ | 360066/414113 [01:25<00:12, 4268.57it/s]\u001b[A\n",
      " 87%|████████▋ | 360493/414113 [01:25<00:12, 4248.82it/s]\u001b[A\n",
      " 87%|████████▋ | 360918/414113 [01:25<00:12, 4222.26it/s]\u001b[A\n",
      " 87%|████████▋ | 361351/414113 [01:25<00:12, 4253.36it/s]\u001b[A\n",
      " 87%|████████▋ | 361790/414113 [01:25<00:12, 4293.03it/s]\u001b[A\n",
      " 87%|████████▋ | 362220/414113 [01:25<00:12, 4286.56it/s]\u001b[A\n",
      " 88%|████████▊ | 362649/414113 [01:25<00:12, 4239.89it/s]\u001b[A\n",
      " 88%|████████▊ | 363074/414113 [01:25<00:12, 4225.54it/s]\u001b[A\n",
      " 88%|████████▊ | 363497/414113 [01:25<00:12, 4188.69it/s]\u001b[A\n",
      " 88%|████████▊ | 363917/414113 [01:25<00:12, 4159.09it/s]\u001b[A\n",
      " 88%|████████▊ | 364339/414113 [01:26<00:11, 4176.49it/s]\u001b[A\n",
      " 88%|████████▊ | 364767/414113 [01:26<00:11, 4204.87it/s]\u001b[A\n",
      " 88%|████████▊ | 365191/414113 [01:26<00:11, 4214.02it/s]\u001b[A\n",
      " 88%|████████▊ | 365618/414113 [01:26<00:11, 4230.55it/s]\u001b[A\n",
      " 88%|████████▊ | 366042/414113 [01:26<00:11, 4214.38it/s]\u001b[A\n",
      " 88%|████████▊ | 366475/414113 [01:26<00:11, 4247.31it/s]\u001b[A\n",
      " 89%|████████▊ | 366900/414113 [01:26<00:11, 4217.64it/s]\u001b[A\n",
      " 89%|████████▊ | 367329/414113 [01:26<00:11, 4236.16it/s]\u001b[A\n",
      " 89%|████████▉ | 367758/414113 [01:26<00:10, 4249.64it/s]\u001b[A\n",
      " 89%|████████▉ | 368184/414113 [01:26<00:11, 4154.93it/s]\u001b[A\n",
      " 89%|████████▉ | 368612/414113 [01:27<00:10, 4189.77it/s]\u001b[A\n",
      " 89%|████████▉ | 369045/414113 [01:27<00:10, 4226.43it/s]\u001b[A\n",
      " 89%|████████▉ | 369475/414113 [01:27<00:10, 4245.92it/s]\u001b[A\n",
      " 89%|████████▉ | 369900/414113 [01:27<00:10, 4213.57it/s]\u001b[A\n",
      " 89%|████████▉ | 370327/414113 [01:27<00:10, 4227.64it/s]\u001b[A\n",
      " 90%|████████▉ | 370750/414113 [01:27<00:10, 4206.03it/s]\u001b[A\n",
      " 90%|████████▉ | 371176/414113 [01:27<00:10, 4221.17it/s]\u001b[A\n",
      " 90%|████████▉ | 371599/414113 [01:27<00:10, 4203.59it/s]\u001b[A\n",
      " 90%|████████▉ | 372020/414113 [01:27<00:10, 4195.80it/s]\u001b[A\n",
      " 90%|████████▉ | 372440/414113 [01:27<00:09, 4194.41it/s]\u001b[A\n",
      " 90%|█████████ | 372861/414113 [01:28<00:09, 4199.05it/s]\u001b[A\n",
      " 90%|█████████ | 373282/414113 [01:28<00:09, 4199.99it/s]\u001b[A\n",
      " 90%|█████████ | 373705/414113 [01:28<00:09, 4208.22it/s]\u001b[A\n",
      " 90%|█████████ | 374130/414113 [01:28<00:09, 4220.24it/s]\u001b[A\n",
      " 90%|█████████ | 374562/414113 [01:28<00:09, 4247.38it/s]\u001b[A\n",
      " 91%|█████████ | 374987/414113 [01:28<00:09, 4246.15it/s]\u001b[A\n",
      " 91%|█████████ | 375418/414113 [01:28<00:09, 4264.32it/s]\u001b[A\n",
      " 91%|█████████ | 375845/414113 [01:28<00:09, 4189.20it/s]\u001b[A\n",
      " 91%|█████████ | 376270/414113 [01:28<00:08, 4205.86it/s]\u001b[A\n",
      " 91%|█████████ | 376693/414113 [01:28<00:08, 4210.88it/s]\u001b[A\n",
      " 91%|█████████ | 377118/414113 [01:29<00:08, 4221.67it/s]\u001b[A\n",
      " 91%|█████████ | 377544/414113 [01:29<00:08, 4230.50it/s]\u001b[A\n",
      " 91%|█████████▏| 377972/414113 [01:29<00:08, 4244.86it/s]\u001b[A\n",
      " 91%|█████████▏| 378409/414113 [01:29<00:08, 4280.53it/s]\u001b[A\n",
      " 91%|█████████▏| 378838/414113 [01:29<00:08, 4276.92it/s]\u001b[A\n",
      " 92%|█████████▏| 379266/414113 [01:29<00:08, 4065.45it/s]\u001b[A\n",
      " 92%|█████████▏| 379675/414113 [01:29<00:08, 4048.09it/s]\u001b[A\n",
      " 92%|█████████▏| 380105/414113 [01:29<00:08, 4120.27it/s]\u001b[A\n",
      " 92%|█████████▏| 380519/414113 [01:29<00:08, 4119.74it/s]\u001b[A\n",
      " 92%|█████████▏| 380948/414113 [01:30<00:07, 4167.04it/s]\u001b[A\n",
      " 92%|█████████▏| 381385/414113 [01:30<00:07, 4224.54it/s]\u001b[A\n",
      " 92%|█████████▏| 381809/414113 [01:30<00:07, 4172.97it/s]\u001b[A\n",
      " 92%|█████████▏| 382231/414113 [01:30<00:07, 4186.81it/s]\u001b[A\n",
      " 92%|█████████▏| 382651/414113 [01:30<00:07, 4186.14it/s]\u001b[A\n",
      " 93%|█████████▎| 383078/414113 [01:30<00:07, 4208.91it/s]\u001b[A\n",
      " 93%|█████████▎| 383511/414113 [01:30<00:07, 4241.53it/s]\u001b[A\n",
      " 93%|█████████▎| 383937/414113 [01:30<00:07, 4245.49it/s]\u001b[A\n",
      " 93%|█████████▎| 384362/414113 [01:30<00:07, 4211.02it/s]\u001b[A\n",
      " 93%|█████████▎| 384786/414113 [01:30<00:06, 4217.03it/s]\u001b[A\n",
      " 93%|█████████▎| 385215/414113 [01:31<00:06, 4235.49it/s]\u001b[A\n",
      " 93%|█████████▎| 385647/414113 [01:31<00:06, 4258.58it/s]\u001b[A\n",
      " 93%|█████████▎| 386073/414113 [01:31<00:06, 4238.14it/s]\u001b[A\n",
      " 93%|█████████▎| 386504/414113 [01:31<00:06, 4259.12it/s]\u001b[A\n",
      " 93%|█████████▎| 386938/414113 [01:31<00:06, 4280.34it/s]\u001b[A\n",
      " 94%|█████████▎| 387367/414113 [01:31<00:06, 4167.80it/s]\u001b[A\n",
      " 94%|█████████▎| 387806/414113 [01:31<00:06, 4229.63it/s]\u001b[A\n",
      " 94%|█████████▍| 388234/414113 [01:31<00:06, 4243.73it/s]\u001b[A\n",
      " 94%|█████████▍| 388659/414113 [01:31<00:06, 4185.42it/s]\u001b[A\n",
      " 94%|█████████▍| 389079/414113 [01:31<00:05, 4187.53it/s]\u001b[A\n",
      " 94%|█████████▍| 389502/414113 [01:32<00:05, 4199.46it/s]\u001b[A\n",
      " 94%|█████████▍| 389923/414113 [01:32<00:05, 4175.73it/s]\u001b[A\n",
      " 94%|█████████▍| 390351/414113 [01:32<00:05, 4205.30it/s]\u001b[A\n",
      " 94%|█████████▍| 390772/414113 [01:32<00:05, 4130.41it/s]\u001b[A\n",
      " 94%|█████████▍| 391186/414113 [01:32<00:05, 4097.67it/s]\u001b[A\n",
      " 95%|█████████▍| 391605/414113 [01:32<00:05, 4123.61it/s]\u001b[A\n",
      " 95%|█████████▍| 392018/414113 [01:32<00:05, 4084.96it/s]\u001b[A\n",
      " 95%|█████████▍| 392444/414113 [01:32<00:05, 4134.08it/s]\u001b[A\n",
      " 95%|█████████▍| 392866/414113 [01:32<00:05, 4158.24it/s]\u001b[A\n",
      " 95%|█████████▍| 393283/414113 [01:32<00:05, 4158.29it/s]\u001b[A\n",
      " 95%|█████████▌| 393711/414113 [01:33<00:04, 4193.39it/s]\u001b[A\n",
      " 95%|█████████▌| 394144/414113 [01:33<00:04, 4233.42it/s]\u001b[A\n",
      " 95%|█████████▌| 394568/414113 [01:33<00:04, 4228.90it/s]\u001b[A\n",
      " 95%|█████████▌| 394992/414113 [01:33<00:04, 4223.87it/s]\u001b[A\n",
      " 95%|█████████▌| 395415/414113 [01:33<00:04, 4222.33it/s]\u001b[A\n",
      " 96%|█████████▌| 395847/414113 [01:33<00:04, 4250.13it/s]\u001b[A\n",
      " 96%|█████████▌| 396278/414113 [01:33<00:04, 4266.14it/s]\u001b[A\n",
      " 96%|█████████▌| 396709/414113 [01:33<00:04, 4275.95it/s]\u001b[A\n",
      " 96%|█████████▌| 397137/414113 [01:33<00:03, 4263.44it/s]\u001b[A\n",
      " 96%|█████████▌| 397564/414113 [01:33<00:03, 4265.04it/s]\u001b[A\n",
      " 96%|█████████▌| 397991/414113 [01:34<00:03, 4251.91it/s]\u001b[A\n",
      " 96%|█████████▌| 398417/414113 [01:34<00:03, 4252.85it/s]\u001b[A\n",
      " 96%|█████████▋| 398852/414113 [01:34<00:03, 4281.35it/s]\u001b[A\n",
      " 96%|█████████▋| 399281/414113 [01:34<00:03, 4244.76it/s]\u001b[A\n",
      " 97%|█████████▋| 399706/414113 [01:34<00:03, 4218.43it/s]\u001b[A\n",
      " 97%|█████████▋| 400132/414113 [01:34<00:03, 4227.73it/s]\u001b[A\n",
      " 97%|█████████▋| 400556/414113 [01:34<00:03, 4230.60it/s]\u001b[A\n",
      " 97%|█████████▋| 400986/414113 [01:34<00:03, 4249.43it/s]\u001b[A\n",
      " 97%|█████████▋| 401418/414113 [01:34<00:02, 4268.97it/s]\u001b[A\n",
      " 97%|█████████▋| 401864/414113 [01:34<00:02, 4324.16it/s]\u001b[A\n",
      " 97%|█████████▋| 402297/414113 [01:35<00:02, 4298.43it/s]\u001b[A\n",
      " 97%|█████████▋| 402728/414113 [01:35<00:02, 4296.85it/s]\u001b[A\n",
      " 97%|█████████▋| 403158/414113 [01:35<00:02, 4286.77it/s]\u001b[A\n",
      " 97%|█████████▋| 403587/414113 [01:35<00:02, 4231.14it/s]\u001b[A\n",
      " 98%|█████████▊| 404011/414113 [01:35<00:02, 4226.28it/s]\u001b[A\n",
      " 98%|█████████▊| 404439/414113 [01:35<00:02, 4240.86it/s]\u001b[A\n",
      " 98%|█████████▊| 404866/414113 [01:35<00:02, 4246.67it/s]\u001b[A\n",
      " 98%|█████████▊| 405291/414113 [01:35<00:02, 4228.26it/s]\u001b[A\n",
      " 98%|█████████▊| 405729/414113 [01:35<00:01, 4271.01it/s]\u001b[A\n",
      " 98%|█████████▊| 406157/414113 [01:35<00:01, 4242.87it/s]\u001b[A\n",
      " 98%|█████████▊| 406595/414113 [01:36<00:01, 4280.20it/s]\u001b[A\n",
      " 98%|█████████▊| 407024/414113 [01:36<00:01, 4278.79it/s]\u001b[A\n",
      " 98%|█████████▊| 407458/414113 [01:36<00:01, 4294.75it/s]\u001b[A\n",
      " 98%|█████████▊| 407888/414113 [01:36<00:01, 4268.78it/s]\u001b[A\n",
      " 99%|█████████▊| 408317/414113 [01:36<00:01, 4274.44it/s]\u001b[A\n",
      " 99%|█████████▊| 408745/414113 [01:36<00:01, 4275.03it/s]\u001b[A\n",
      " 99%|█████████▉| 409173/414113 [01:36<00:01, 4276.04it/s]\u001b[A\n",
      " 99%|█████████▉| 409602/414113 [01:36<00:01, 4277.55it/s]\u001b[A\n",
      " 99%|█████████▉| 410030/414113 [01:36<00:00, 4232.94it/s]\u001b[A\n",
      " 99%|█████████▉| 410459/414113 [01:36<00:00, 4248.81it/s]\u001b[A\n",
      " 99%|█████████▉| 410911/414113 [01:37<00:00, 4324.87it/s]\u001b[A\n",
      " 99%|█████████▉| 411351/414113 [01:37<00:00, 4345.12it/s]\u001b[A\n",
      " 99%|█████████▉| 411786/414113 [01:37<00:00, 4338.41it/s]\u001b[A\n",
      "100%|█████████▉| 412221/414113 [01:37<00:00, 4332.15it/s]\u001b[A\n",
      "100%|█████████▉| 412677/414113 [01:37<00:00, 4395.92it/s]\u001b[A\n",
      "100%|█████████▉| 413117/414113 [01:37<00:00, 4382.16it/s]\u001b[A\n",
      "100%|█████████▉| 413556/414113 [01:37<00:00, 4380.12it/s]\u001b[A\n",
      "100%|█████████▉| 413995/414113 [01:37<00:00, 4335.20it/s]\u001b[A\n",
      "100%|██████████| 414113/414113 [01:37<00:00, 4233.28it/s]\u001b[ADownloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.torch/models/resnet50-19c8e357.pth\n",
      "\n",
      "  0%|          | 0/102502400 [00:00<?, ?it/s]\u001b[A\n",
      "  4%|▍         | 3899392/102502400 [00:00<00:02, 38958568.17it/s]\u001b[A\n",
      " 13%|█▎        | 13500416/102502400 [00:00<00:01, 47408191.62it/s]\u001b[A\n",
      " 22%|██▏       | 22970368/102502400 [00:00<00:01, 55758475.12it/s]\u001b[A\n",
      " 31%|███▏      | 32112640/102502400 [00:00<00:01, 63145289.19it/s]\u001b[A\n",
      " 41%|████      | 41517056/102502400 [00:00<00:00, 70046711.66it/s]\u001b[A\n",
      " 50%|████▉     | 50782208/102502400 [00:00<00:00, 75569377.55it/s]\u001b[A\n",
      " 60%|█████▉    | 61145088/102502400 [00:00<00:00, 82240718.57it/s]\u001b[A\n",
      " 70%|██████▉   | 71573504/102502400 [00:00<00:00, 87808177.20it/s]\u001b[A\n",
      " 79%|███████▉  | 80846848/102502400 [00:00<00:00, 89217185.40it/s]\u001b[A\n",
      " 88%|████████▊ | 90185728/102502400 [00:01<00:00, 90415567.80it/s]\u001b[A\n",
      " 97%|█████████▋| 99442688/102502400 [00:01<00:00, 90591622.16it/s]\u001b[A\n",
      "100%|██████████| 102502400/102502400 [00:01<00:00, 90258763.02it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done (t=0.86s)\n",
      "creating index...\n",
      "index created!\n",
      "Obtaining caption lengths...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "import sys\n",
    "sys.path.append('/opt/cocoapi/PythonAPI')\n",
    "from pycocotools.coco import COCO\n",
    "from data_loader import get_loader\n",
    "from model import EncoderCNN, DecoderRNN\n",
    "import math\n",
    "import torch.optim as optim\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "## TODO #1: Select appropriate values for the Python variables below.\n",
    "batch_size = 64          # batch size\n",
    "vocab_threshold = 5       # minimum word count threshold\n",
    "vocab_from_file = True    # if True, load existing vocab file\n",
    "embed_size = 512           # dimensionality of image and word embeddings\n",
    "hidden_size = 512          # number of features in hidden state of the RNN decoder\n",
    "num_epochs = 3             # number of training epochs\n",
    "save_every = 1             # determines frequency of saving model weights\n",
    "print_every = 100          # determines window for printing average loss\n",
    "log_file = 'training_log.txt'       # name of file with saved training loss and perplexity\n",
    "\n",
    "# (Optional) TODO #2: Amend the image transform below.\n",
    "transform_train = transforms.Compose([ \n",
    "    transforms.Resize(256),                          # smaller edge of image resized to 256\n",
    "    transforms.RandomCrop(224),                      # get 224x224 crop from random location\n",
    "    transforms.RandomHorizontalFlip(),               # horizontally flip image with probability=0.5\n",
    "    transforms.ToTensor(),                           # convert the PIL Image to a tensor\n",
    "    transforms.Normalize((0.485, 0.456, 0.406),      # normalize image for pre-trained model\n",
    "                         (0.229, 0.224, 0.225))])\n",
    "\n",
    "# Build data loader.\n",
    "data_loader = get_loader(transform=transform_train,\n",
    "                         mode='train',\n",
    "                         batch_size=batch_size,\n",
    "                         vocab_threshold=vocab_threshold,\n",
    "                         vocab_from_file=vocab_from_file)\n",
    "\n",
    "# The size of the vocabulary.\n",
    "vocab_size = len(data_loader.dataset.vocab)\n",
    "\n",
    "# Initialize the encoder and decoder. \n",
    "encoder = EncoderCNN(embed_size)\n",
    "decoder = DecoderRNN(embed_size, hidden_size, vocab_size)\n",
    "\n",
    "# Move models to GPU if CUDA is available. \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "encoder.to(device)\n",
    "decoder.to(device)\n",
    "\n",
    "# Define the loss function. \n",
    "criterion = nn.CrossEntropyLoss().cuda() if torch.cuda.is_available() else nn.CrossEntropyLoss()\n",
    "\n",
    "# TODO #3: Specify the learnable parameters of the model.\n",
    "params = list(decoder.parameters()) + list(encoder.embed.parameters()) \n",
    "\n",
    "# TODO #4: Define the optimizer.\n",
    "optimizer = optim.Adam(params)\n",
    "\n",
    "# Set the total number of training steps per epoch.\n",
    "total_step = math.ceil(len(data_loader.dataset.caption_lengths) / data_loader.batch_sampler.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step2'></a>\n",
    "## Step 2: Train your Model\n",
    "\n",
    "Once you have executed the code cell in **Step 1**, the training procedure below should run without issue.  \n",
    "\n",
    "It is completely fine to leave the code cell below as-is without modifications to train your model.  However, if you would like to modify the code used to train the model below, you must ensure that your changes are easily parsed by your reviewer.  In other words, make sure to provide appropriate comments to describe how your code works!  \n",
    "\n",
    "You may find it useful to load saved weights to resume training.  In that case, note the names of the files containing the encoder and decoder weights that you'd like to load (`encoder_file` and `decoder_file`).  Then you can load the weights by using the lines below:\n",
    "\n",
    "```python\n",
    "# Load pre-trained weights before resuming training.\n",
    "encoder.load_state_dict(torch.load(os.path.join('./models', encoder_file)))\n",
    "decoder.load_state_dict(torch.load(os.path.join('./models', decoder_file)))\n",
    "```\n",
    "\n",
    "While trying out parameters, make sure to take extensive notes and record the settings that you used in your various training runs.  In particular, you don't want to encounter a situation where you've trained a model for several hours but can't remember what settings you used :).\n",
    "\n",
    "### A Note on Tuning Hyperparameters\n",
    "\n",
    "To figure out how well your model is doing, you can look at how the training loss and perplexity evolve during training - and for the purposes of this project, you are encouraged to amend the hyperparameters based on this information.  \n",
    "\n",
    "However, this will not tell you if your model is overfitting to the training data, and, unfortunately, overfitting is a problem that is commonly encountered when training image captioning models.  \n",
    "\n",
    "For this project, you need not worry about overfitting. **This project does not have strict requirements regarding the performance of your model**, and you just need to demonstrate that your model has learned **_something_** when you generate captions on the test data.  For now, we strongly encourage you to train your model for the suggested 3 epochs without worrying about performance; then, you should immediately transition to the next notebook in the sequence (**3_Inference.ipynb**) to see how your model performs on the test data.  If your model needs to be changed, you can come back to this notebook, amend hyperparameters (if necessary), and re-train the model.\n",
    "\n",
    "That said, if you would like to go above and beyond in this project, you can read about some approaches to minimizing overfitting in section 4.3.1 of [this paper](http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7505636).  In the next (optional) step of this notebook, we provide some guidance for assessing the performance on the validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [100/6471], Loss: 3.5928, Perplexity: 36.3364\n",
      "Epoch [1/3], Step [200/6471], Loss: 3.3876, Perplexity: 29.5957\n",
      "Epoch [1/3], Step [300/6471], Loss: 3.2661, Perplexity: 26.2101\n",
      "Epoch [1/3], Step [400/6471], Loss: 3.2133, Perplexity: 24.8602\n",
      "Epoch [1/3], Step [500/6471], Loss: 3.0286, Perplexity: 20.6676\n",
      "Epoch [1/3], Step [600/6471], Loss: 3.1495, Perplexity: 23.3254\n",
      "Epoch [1/3], Step [700/6471], Loss: 2.9112, Perplexity: 18.3796\n",
      "Epoch [1/3], Step [800/6471], Loss: 3.0093, Perplexity: 20.2724\n",
      "Epoch [1/3], Step [900/6471], Loss: 2.9135, Perplexity: 18.4217\n",
      "Epoch [1/3], Step [1000/6471], Loss: 2.7864, Perplexity: 16.2222\n",
      "Epoch [1/3], Step [1100/6471], Loss: 2.5979, Perplexity: 13.4361\n",
      "Epoch [1/3], Step [1200/6471], Loss: 2.4924, Perplexity: 12.0908\n",
      "Epoch [1/3], Step [1300/6471], Loss: 2.8979, Perplexity: 18.1352\n",
      "Epoch [1/3], Step [1400/6471], Loss: 2.7881, Perplexity: 16.2500\n",
      "Epoch [1/3], Step [1500/6471], Loss: 2.4472, Perplexity: 11.5565\n",
      "Epoch [1/3], Step [1600/6471], Loss: 2.7814, Perplexity: 16.1409\n",
      "Epoch [1/3], Step [1700/6471], Loss: 3.0029, Perplexity: 20.1441\n",
      "Epoch [1/3], Step [1800/6471], Loss: 3.0227, Perplexity: 20.54623\n",
      "Epoch [1/3], Step [1900/6471], Loss: 2.4849, Perplexity: 12.0002\n",
      "Epoch [1/3], Step [2000/6471], Loss: 2.3979, Perplexity: 11.0000\n",
      "Epoch [1/3], Step [2100/6471], Loss: 2.9755, Perplexity: 19.5993\n",
      "Epoch [1/3], Step [2200/6471], Loss: 2.2709, Perplexity: 9.68817\n",
      "Epoch [1/3], Step [2300/6471], Loss: 2.4693, Perplexity: 11.8139\n",
      "Epoch [1/3], Step [2400/6471], Loss: 2.7896, Perplexity: 16.2748\n",
      "Epoch [1/3], Step [2500/6471], Loss: 2.4007, Perplexity: 11.0304\n",
      "Epoch [1/3], Step [2600/6471], Loss: 2.6890, Perplexity: 14.7167\n",
      "Epoch [1/3], Step [2700/6471], Loss: 2.1146, Perplexity: 8.28596\n",
      "Epoch [1/3], Step [2800/6471], Loss: 2.6007, Perplexity: 13.4725\n",
      "Epoch [1/3], Step [2900/6471], Loss: 2.3523, Perplexity: 10.5098\n",
      "Epoch [1/3], Step [3000/6471], Loss: 2.4574, Perplexity: 11.6746\n",
      "Epoch [1/3], Step [3100/6471], Loss: 2.3767, Perplexity: 10.7692\n",
      "Epoch [1/3], Step [3200/6471], Loss: 2.3635, Perplexity: 10.6279\n",
      "Epoch [1/3], Step [3300/6471], Loss: 2.2311, Perplexity: 9.31053\n",
      "Epoch [1/3], Step [3400/6471], Loss: 2.1436, Perplexity: 8.53049\n",
      "Epoch [1/3], Step [3500/6471], Loss: 2.5834, Perplexity: 13.2424\n",
      "Epoch [1/3], Step [3600/6471], Loss: 2.2201, Perplexity: 9.20800\n",
      "Epoch [1/3], Step [3700/6471], Loss: 2.8167, Perplexity: 16.7212\n",
      "Epoch [1/3], Step [3800/6471], Loss: 2.3055, Perplexity: 10.0289\n",
      "Epoch [1/3], Step [3900/6471], Loss: 2.2574, Perplexity: 9.55862\n",
      "Epoch [1/3], Step [4000/6471], Loss: 2.1902, Perplexity: 8.93705\n",
      "Epoch [1/3], Step [4100/6471], Loss: 2.3266, Perplexity: 10.2427\n",
      "Epoch [1/3], Step [4200/6471], Loss: 3.2960, Perplexity: 27.0053\n",
      "Epoch [1/3], Step [4300/6471], Loss: 2.2106, Perplexity: 9.12081\n",
      "Epoch [1/3], Step [4400/6471], Loss: 2.2093, Perplexity: 9.10958\n",
      "Epoch [1/3], Step [4500/6471], Loss: 2.0866, Perplexity: 8.05779\n",
      "Epoch [1/3], Step [4600/6471], Loss: 2.1340, Perplexity: 8.44905\n",
      "Epoch [1/3], Step [4700/6471], Loss: 2.0043, Perplexity: 7.42091\n",
      "Epoch [1/3], Step [4800/6471], Loss: 2.2791, Perplexity: 9.76748\n",
      "Epoch [1/3], Step [4900/6471], Loss: 1.8919, Perplexity: 6.63171\n",
      "Epoch [1/3], Step [5000/6471], Loss: 2.0952, Perplexity: 8.12707\n",
      "Epoch [1/3], Step [5100/6471], Loss: 2.3156, Perplexity: 10.1309\n",
      "Epoch [1/3], Step [5200/6471], Loss: 2.4397, Perplexity: 11.4700\n",
      "Epoch [1/3], Step [5300/6471], Loss: 2.1282, Perplexity: 8.39968\n",
      "Epoch [1/3], Step [5400/6471], Loss: 2.3183, Perplexity: 10.1586\n",
      "Epoch [1/3], Step [5500/6471], Loss: 2.0863, Perplexity: 8.054809\n",
      "Epoch [1/3], Step [5600/6471], Loss: 4.4912, Perplexity: 89.2296\n",
      "Epoch [1/3], Step [5700/6471], Loss: 2.0898, Perplexity: 8.08352\n",
      "Epoch [1/3], Step [5800/6471], Loss: 2.3055, Perplexity: 10.0290\n",
      "Epoch [1/3], Step [5900/6471], Loss: 2.0799, Perplexity: 8.00337\n",
      "Epoch [1/3], Step [6000/6471], Loss: 2.1493, Perplexity: 8.57903\n",
      "Epoch [1/3], Step [6100/6471], Loss: 2.0265, Perplexity: 7.58755\n",
      "Epoch [1/3], Step [6200/6471], Loss: 2.0372, Perplexity: 7.66937\n",
      "Epoch [1/3], Step [6300/6471], Loss: 2.0262, Perplexity: 7.58555\n",
      "Epoch [1/3], Step [6400/6471], Loss: 2.0916, Perplexity: 8.09802\n",
      "Epoch [2/3], Step [100/6471], Loss: 2.0538, Perplexity: 7.797254\n",
      "Epoch [2/3], Step [200/6471], Loss: 2.1288, Perplexity: 8.40470\n",
      "Epoch [2/3], Step [300/6471], Loss: 1.9043, Perplexity: 6.71509\n",
      "Epoch [2/3], Step [400/6471], Loss: 2.7606, Perplexity: 15.8093\n",
      "Epoch [2/3], Step [500/6471], Loss: 2.4302, Perplexity: 11.3617\n",
      "Epoch [2/3], Step [600/6471], Loss: 2.0360, Perplexity: 7.65982\n",
      "Epoch [2/3], Step [700/6471], Loss: 1.9239, Perplexity: 6.84781\n",
      "Epoch [2/3], Step [800/6471], Loss: 1.9552, Perplexity: 7.06550\n",
      "Epoch [2/3], Step [900/6471], Loss: 2.0357, Perplexity: 7.65753\n",
      "Epoch [2/3], Step [1000/6471], Loss: 2.3909, Perplexity: 10.9229\n",
      "Epoch [2/3], Step [1100/6471], Loss: 2.1304, Perplexity: 8.41835\n",
      "Epoch [2/3], Step [1200/6471], Loss: 2.2296, Perplexity: 9.29636\n",
      "Epoch [2/3], Step [1300/6471], Loss: 1.9505, Perplexity: 7.03246\n",
      "Epoch [2/3], Step [1400/6471], Loss: 2.0315, Perplexity: 7.62576\n",
      "Epoch [2/3], Step [1500/6471], Loss: 2.1290, Perplexity: 8.40620\n",
      "Epoch [2/3], Step [1600/6471], Loss: 1.9539, Perplexity: 7.05601\n",
      "Epoch [2/3], Step [1700/6471], Loss: 2.0760, Perplexity: 7.97222\n",
      "Epoch [2/3], Step [1800/6471], Loss: 2.3464, Perplexity: 10.4480\n",
      "Epoch [2/3], Step [1900/6471], Loss: 1.8987, Perplexity: 6.67705\n",
      "Epoch [2/3], Step [2000/6471], Loss: 1.8032, Perplexity: 6.06905\n",
      "Epoch [2/3], Step [2100/6471], Loss: 2.1272, Perplexity: 8.39161\n",
      "Epoch [2/3], Step [2200/6471], Loss: 2.1645, Perplexity: 8.70990\n",
      "Epoch [2/3], Step [2300/6471], Loss: 1.8518, Perplexity: 6.37120\n",
      "Epoch [2/3], Step [2400/6471], Loss: 2.3470, Perplexity: 10.4544\n",
      "Epoch [2/3], Step [2500/6471], Loss: 2.3407, Perplexity: 10.3883\n",
      "Epoch [2/3], Step [2600/6471], Loss: 2.0225, Perplexity: 7.55708\n",
      "Epoch [2/3], Step [2700/6471], Loss: 2.0236, Perplexity: 7.56529\n",
      "Epoch [2/3], Step [2800/6471], Loss: 1.9956, Perplexity: 7.35651\n",
      "Epoch [2/3], Step [2900/6471], Loss: 1.9618, Perplexity: 7.11219\n",
      "Epoch [2/3], Step [3000/6471], Loss: 2.0697, Perplexity: 7.92284\n",
      "Epoch [2/3], Step [3100/6471], Loss: 2.1276, Perplexity: 8.39456\n",
      "Epoch [2/3], Step [3200/6471], Loss: 2.2061, Perplexity: 9.08036\n",
      "Epoch [2/3], Step [3300/6471], Loss: 2.0676, Perplexity: 7.90619\n",
      "Epoch [2/3], Step [3400/6471], Loss: 2.0072, Perplexity: 7.44223\n",
      "Epoch [2/3], Step [3500/6471], Loss: 2.6815, Perplexity: 14.6070\n",
      "Epoch [2/3], Step [3600/6471], Loss: 2.0622, Perplexity: 7.86349\n",
      "Epoch [2/3], Step [3700/6471], Loss: 2.1440, Perplexity: 8.53373\n",
      "Epoch [2/3], Step [3800/6471], Loss: 1.9531, Perplexity: 7.05077\n",
      "Epoch [2/3], Step [3900/6471], Loss: 1.9921, Perplexity: 7.33117\n",
      "Epoch [2/3], Step [4000/6471], Loss: 1.8600, Perplexity: 6.42351\n",
      "Epoch [2/3], Step [4100/6471], Loss: 2.1089, Perplexity: 8.23916\n",
      "Epoch [2/3], Step [4200/6471], Loss: 1.8940, Perplexity: 6.64575\n",
      "Epoch [2/3], Step [4300/6471], Loss: 2.0080, Perplexity: 7.44850\n",
      "Epoch [2/3], Step [4400/6471], Loss: 2.1954, Perplexity: 8.98395\n",
      "Epoch [2/3], Step [4500/6471], Loss: 2.1286, Perplexity: 8.40298\n",
      "Epoch [2/3], Step [4600/6471], Loss: 1.9438, Perplexity: 6.98533\n",
      "Epoch [2/3], Step [4700/6471], Loss: 1.9286, Perplexity: 6.87969\n",
      "Epoch [2/3], Step [4800/6471], Loss: 2.4018, Perplexity: 11.0427\n",
      "Epoch [2/3], Step [4900/6471], Loss: 1.9975, Perplexity: 7.37109\n",
      "Epoch [2/3], Step [5000/6471], Loss: 2.1993, Perplexity: 9.01854\n",
      "Epoch [2/3], Step [5100/6471], Loss: 2.4313, Perplexity: 11.3737\n",
      "Epoch [2/3], Step [5200/6471], Loss: 2.4213, Perplexity: 11.2603\n",
      "Epoch [2/3], Step [5300/6471], Loss: 1.8947, Perplexity: 6.65084\n",
      "Epoch [2/3], Step [5400/6471], Loss: 1.9597, Perplexity: 7.09730\n",
      "Epoch [2/3], Step [5500/6471], Loss: 2.3372, Perplexity: 10.3527\n",
      "Epoch [2/3], Step [5600/6471], Loss: 2.0570, Perplexity: 7.82289\n",
      "Epoch [2/3], Step [5700/6471], Loss: 2.3892, Perplexity: 10.9051\n",
      "Epoch [2/3], Step [5800/6471], Loss: 1.8192, Perplexity: 6.16715\n",
      "Epoch [2/3], Step [5900/6471], Loss: 2.2548, Perplexity: 9.53358\n",
      "Epoch [2/3], Step [6000/6471], Loss: 2.0504, Perplexity: 7.77100\n",
      "Epoch [2/3], Step [6100/6471], Loss: 2.0982, Perplexity: 8.15151\n",
      "Epoch [2/3], Step [6200/6471], Loss: 1.8294, Perplexity: 6.23033\n",
      "Epoch [2/3], Step [6300/6471], Loss: 1.8748, Perplexity: 6.51986\n",
      "Epoch [2/3], Step [6400/6471], Loss: 2.1689, Perplexity: 8.74840\n",
      "Epoch [3/3], Step [100/6471], Loss: 2.0862, Perplexity: 8.054541\n",
      "Epoch [3/3], Step [200/6471], Loss: 2.0487, Perplexity: 7.75761\n",
      "Epoch [3/3], Step [300/6471], Loss: 2.2483, Perplexity: 9.47159\n",
      "Epoch [3/3], Step [400/6471], Loss: 1.8259, Perplexity: 6.20820\n",
      "Epoch [3/3], Step [500/6471], Loss: 1.9357, Perplexity: 6.92913\n",
      "Epoch [3/3], Step [600/6471], Loss: 1.9359, Perplexity: 6.93068\n",
      "Epoch [3/3], Step [700/6471], Loss: 2.1583, Perplexity: 8.65681\n",
      "Epoch [3/3], Step [800/6471], Loss: 1.9087, Perplexity: 6.74450\n",
      "Epoch [3/3], Step [900/6471], Loss: 1.9934, Perplexity: 7.34045\n",
      "Epoch [3/3], Step [1000/6471], Loss: 1.9573, Perplexity: 7.0805\n",
      "Epoch [3/3], Step [1100/6471], Loss: 3.1216, Perplexity: 22.6820\n",
      "Epoch [3/3], Step [1200/6471], Loss: 1.8363, Perplexity: 6.27325\n",
      "Epoch [3/3], Step [1300/6471], Loss: 2.1753, Perplexity: 8.80519\n",
      "Epoch [3/3], Step [1400/6471], Loss: 2.0522, Perplexity: 7.78494\n",
      "Epoch [3/3], Step [1500/6471], Loss: 2.0888, Perplexity: 8.07557\n",
      "Epoch [3/3], Step [1600/6471], Loss: 1.9274, Perplexity: 6.87151\n",
      "Epoch [3/3], Step [1700/6471], Loss: 1.8816, Perplexity: 6.56411\n",
      "Epoch [3/3], Step [1800/6471], Loss: 2.0125, Perplexity: 7.48230\n",
      "Epoch [3/3], Step [1900/6471], Loss: 2.0864, Perplexity: 8.05613\n",
      "Epoch [3/3], Step [2000/6471], Loss: 2.1830, Perplexity: 8.873302\n",
      "Epoch [3/3], Step [2100/6471], Loss: 1.9875, Perplexity: 7.29713\n",
      "Epoch [3/3], Step [2200/6471], Loss: 1.9751, Perplexity: 7.20701\n",
      "Epoch [3/3], Step [2300/6471], Loss: 2.2811, Perplexity: 9.78721\n",
      "Epoch [3/3], Step [2400/6471], Loss: 1.9806, Perplexity: 7.24728\n",
      "Epoch [3/3], Step [2500/6471], Loss: 2.0587, Perplexity: 7.83608\n",
      "Epoch [3/3], Step [2600/6471], Loss: 2.0390, Perplexity: 7.68278\n",
      "Epoch [3/3], Step [2700/6471], Loss: 2.2564, Perplexity: 9.54896\n",
      "Epoch [3/3], Step [2800/6471], Loss: 1.9199, Perplexity: 6.82038\n",
      "Epoch [3/3], Step [2900/6471], Loss: 1.7854, Perplexity: 5.96188\n",
      "Epoch [3/3], Step [3000/6471], Loss: 2.4059, Perplexity: 11.0885\n",
      "Epoch [3/3], Step [3100/6471], Loss: 2.0811, Perplexity: 8.01369\n",
      "Epoch [3/3], Step [3200/6471], Loss: 1.8317, Perplexity: 6.24480\n",
      "Epoch [3/3], Step [3300/6471], Loss: 1.8791, Perplexity: 6.54778\n",
      "Epoch [3/3], Step [3400/6471], Loss: 1.8470, Perplexity: 6.34092\n",
      "Epoch [3/3], Step [3500/6471], Loss: 1.8992, Perplexity: 6.68061\n",
      "Epoch [3/3], Step [3600/6471], Loss: 2.3443, Perplexity: 10.4260\n",
      "Epoch [3/3], Step [3700/6471], Loss: 2.5935, Perplexity: 13.3768\n",
      "Epoch [3/3], Step [3800/6471], Loss: 2.1111, Perplexity: 8.25779\n",
      "Epoch [3/3], Step [3900/6471], Loss: 1.8389, Perplexity: 6.28989\n",
      "Epoch [3/3], Step [4000/6471], Loss: 1.9633, Perplexity: 7.12265\n",
      "Epoch [3/3], Step [4100/6471], Loss: 1.8949, Perplexity: 6.65168\n",
      "Epoch [3/3], Step [4200/6471], Loss: 2.0503, Perplexity: 7.77030\n",
      "Epoch [3/3], Step [4300/6471], Loss: 1.9721, Perplexity: 7.18563\n",
      "Epoch [3/3], Step [4400/6471], Loss: 1.8785, Perplexity: 6.54394\n",
      "Epoch [3/3], Step [4500/6471], Loss: 1.9342, Perplexity: 6.91870\n",
      "Epoch [3/3], Step [4600/6471], Loss: 2.8162, Perplexity: 16.7132\n",
      "Epoch [3/3], Step [4700/6471], Loss: 1.8386, Perplexity: 6.28742\n",
      "Epoch [3/3], Step [4800/6471], Loss: 1.9681, Perplexity: 7.15716\n",
      "Epoch [3/3], Step [4900/6471], Loss: 1.8395, Perplexity: 6.29364\n",
      "Epoch [3/3], Step [5000/6471], Loss: 1.7930, Perplexity: 6.00736\n",
      "Epoch [3/3], Step [5100/6471], Loss: 1.9661, Perplexity: 7.14287\n",
      "Epoch [3/3], Step [5200/6471], Loss: 1.8138, Perplexity: 6.13400\n",
      "Epoch [3/3], Step [5300/6471], Loss: 1.9147, Perplexity: 6.78467\n",
      "Epoch [3/3], Step [5400/6471], Loss: 2.3732, Perplexity: 10.7315\n",
      "Epoch [3/3], Step [5500/6471], Loss: 1.8915, Perplexity: 6.62924\n",
      "Epoch [3/3], Step [5600/6471], Loss: 2.0119, Perplexity: 7.47720\n",
      "Epoch [3/3], Step [5700/6471], Loss: 2.0043, Perplexity: 7.42114\n",
      "Epoch [3/3], Step [5800/6471], Loss: 2.0370, Perplexity: 7.66746\n",
      "Epoch [3/3], Step [5900/6471], Loss: 2.0455, Perplexity: 7.73328\n",
      "Epoch [3/3], Step [6000/6471], Loss: 1.8919, Perplexity: 6.63227\n",
      "Epoch [3/3], Step [6100/6471], Loss: 1.8175, Perplexity: 6.15673\n",
      "Epoch [3/3], Step [6200/6471], Loss: 1.9739, Perplexity: 7.19892\n",
      "Epoch [3/3], Step [6300/6471], Loss: 1.9184, Perplexity: 6.81021\n",
      "Epoch [3/3], Step [6400/6471], Loss: 1.9203, Perplexity: 6.822947\n",
      "Epoch [3/3], Step [6471/6471], Loss: 2.0350, Perplexity: 7.65264"
     ]
    }
   ],
   "source": [
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "import time\n",
    "\n",
    "# Open the training log file.\n",
    "f = open(log_file, 'w')\n",
    "\n",
    "old_time = time.time()\n",
    "response = requests.request(\"GET\", \n",
    "                            \"http://metadata.google.internal/computeMetadata/v1/instance/attributes/keep_alive_token\", \n",
    "                            headers={\"Metadata-Flavor\":\"Google\"})\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    \n",
    "    for i_step in range(1, total_step+1):\n",
    "        \n",
    "        if time.time() - old_time > 60:\n",
    "            old_time = time.time()\n",
    "            requests.request(\"POST\", \n",
    "                             \"https://nebula.udacity.com/api/v1/remote/keep-alive\", \n",
    "                             headers={'Authorization': \"STAR \" + response.text})\n",
    "        \n",
    "        # Randomly sample a caption length, and sample indices with that length.\n",
    "        indices = data_loader.dataset.get_train_indices()\n",
    "        # Create and assign a batch sampler to retrieve a batch with the sampled indices.\n",
    "        new_sampler = data.sampler.SubsetRandomSampler(indices=indices)\n",
    "        data_loader.batch_sampler.sampler = new_sampler\n",
    "        \n",
    "        # Obtain the batch.\n",
    "        images, captions = next(iter(data_loader))\n",
    "\n",
    "        # Move batch of images and captions to GPU if CUDA is available.\n",
    "        images = images.to(device)\n",
    "        captions = captions.to(device)\n",
    "        \n",
    "        # Zero the gradients.\n",
    "        decoder.zero_grad()\n",
    "        encoder.zero_grad()\n",
    "        \n",
    "        # Pass the inputs through the CNN-RNN model.\n",
    "        features = encoder(images)\n",
    "        outputs = decoder(features, captions)\n",
    "        \n",
    "        # Calculate the batch loss.\n",
    "        loss = criterion(outputs.view(-1, vocab_size), captions.view(-1))\n",
    "        \n",
    "        # Backward pass.\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the parameters in the optimizer.\n",
    "        optimizer.step()\n",
    "            \n",
    "        # Get training statistics.\n",
    "        stats = 'Epoch [%d/%d], Step [%d/%d], Loss: %.4f, Perplexity: %5.4f' % (epoch, num_epochs, i_step, total_step, loss.item(), np.exp(loss.item()))\n",
    "        \n",
    "        # Print training statistics (on same line).\n",
    "        print('\\r' + stats, end=\"\")\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "        # Print training statistics to file.\n",
    "        f.write(stats + '\\n')\n",
    "        f.flush()\n",
    "        \n",
    "        # Print training statistics (on different line).\n",
    "        if i_step % print_every == 0:\n",
    "            print('\\r' + stats)\n",
    "            \n",
    "    # Save the weights.\n",
    "    if epoch % save_every == 0:\n",
    "        torch.save(decoder.state_dict(), os.path.join('./models', 'decoder-%d.pkl' % epoch))\n",
    "        torch.save(encoder.state_dict(), os.path.join('./models', 'encoder-%d.pkl' % epoch))\n",
    "\n",
    "# Close the training log file.\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step3'></a>\n",
    "## Step 3: (Optional) Validate your Model\n",
    "\n",
    "To assess potential overfitting, one approach is to assess performance on a validation set.  If you decide to do this **optional** task, you are required to first complete all of the steps in the next notebook in the sequence (**3_Inference.ipynb**); as part of that notebook, you will write and test code (specifically, the `sample` method in the `DecoderRNN` class) that uses your RNN decoder to generate captions.  That code will prove incredibly useful here. \n",
    "\n",
    "If you decide to validate your model, please do not edit the data loader in **data_loader.py**.  Instead, create a new file named **data_loader_val.py** containing the code for obtaining the data loader for the validation data.  You can access:\n",
    "- the validation images at filepath `'/opt/cocoapi/images/train2014/'`, and\n",
    "- the validation image caption annotation file at filepath `'/opt/cocoapi/annotations/captions_val2014.json'`.\n",
    "\n",
    "The suggested approach to validating your model involves creating a json file such as [this one](https://github.com/cocodataset/cocoapi/blob/master/results/captions_val2014_fakecap_results.json) containing your model's predicted captions for the validation images.  Then, you can write your own script or use one that you [find online](https://github.com/tylin/coco-caption) to calculate the BLEU score of your model.  You can read more about the BLEU score, along with other evaluation metrics (such as TEOR and Cider) in section 4.1 of [this paper](https://arxiv.org/pdf/1411.4555.pdf).  For more information about how to use the annotation file, check out the [website](http://cocodataset.org/#download) for the COCO dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Optional) TODO: Validate your model."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
